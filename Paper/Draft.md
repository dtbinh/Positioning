# Draft

_[Abstract: ... ]_

-----

<!--TOC-->


# 1. INTRODUCTION

{{Introduction.md}}


# 2. LITERATURE REVIEW

{{Literature review.md}}


# 3. MODEL & METHODOLOGY

{{Methodology.md}}


# 4. ANALYSIS

{{Analysis.md}}


## 4.3 Decision rules with foresight

When a firm chooses its own location, the location of the other competing firms is unknown. The firm may try to predict the location of competing firms. However if multiple firms use this approach then the location outcome that each firm is trying to predict will depend on predictions that the firm and the other firms form. As Arthur (2014, p.175) writes *”predictions are forming a world those predictions are trying to forecast”*. This self-referential loop leads to logical indeterminacy and the maximisation problem of the firm is ill defined and cannot be solved by means of deductive reasoning. 

The two decision rules discussed in this section rely on inductive reasoning. The firm holds several hypotheses and uses these to make predictions on how competing firms will locate. A hypothesis consists of a proposition that might not hold true and so contrary evidence weakens the hypothesis. The firm tests its hypotheses by comparing the predicted location of the other firms to the observed locations. Thereby the firm learns which hypotheses are plausible and thus applicable moving forward. Predictions are made using the hypothesis that worked best in the past. The firm locates -- like the *maxcov* firm -- such that it maximises its market share, but uses the predicted location of all competing firms rather than their current location. In the first decision rule the firm is endowed with a fixed set of hypotheses. These hypotheses are exogenously given and do not change over time. Only the accuracy of each hypothesis changes in pace with its predictions being tested. I refer to this decision rule as *maxcov-inductor*, since the firm uses inductive reasoning. The second decision rule is an expansion of the *maxcov-inductor* rule, but the firm gradually discards poorly performing hypotheses and forms new hypotheses. If possible new hypotheses should perform at par or better than the existing hypotheses. Therefore new hypotheses are formed through an evolutionary process that mutates and fuses the best existing hypotheses. Replacing poorly performing hypothesis is another way in which learning takes place -- leading firms to make better predictions. Hypotheses are endogenous in this decision rule. I refer to this rule as the *maxcov-inductor-GA*, since a genetic algorithm generates the new hypotheses. I use two decision rules such that I can separate the effects from respectively inductive reasoning and endogenously determined hypotheses. The two decision rules allow the effects to be analysed in turn.

The following method is a modified version of the method first developed for *The Santa Fe Institute Artificial Stock Market Model* and described by Arthur (2014, chapter 3) and Arthur, Holland, LeBaron, Palmer and Tayler (1996). In the stock market model multiple agents try to predict the stock price. Each agent faces a single unknown outcome. The agent’s demand for shares depends on the agent’s predicted stock price, i.e. the agent’s action depends on a single prediction. And the actual stock price rely upon the aggregated demand of all agents. In this paper an agent or a firm attempts to predict the future location of all other firms. Each firm faces $N-1$ unknown outcomes. The firm locates based on its predicted location of competing firms, i.e. the action of the firm depends on multiple predictions. Thus the most significant modification is going from a setting with many-to-one predictions to a setting with many-to-many predictions. Additionally the stock price is one-dimensional -- it can go up or down. Whereas the position of the firm is two-dimensional. The firm can relocate in any 360 degree direction. This however only requires a slight modification to the forecasting model used in the method.

**Maxcov-Inductor:**
A firm with the *maxcov-inductor* decision rule maintains several hypotheses on how competing firms locate. The firm uses the hypothesis that fits the current state and that previously proved most accurate to forecast the future location of a competing firm. When the firm chooses its own location it relies on the predicted location of all competing firms.

The firm is endowed with $M$ number of hypotheses. While each hypothesis might only be relevant to a narrow set of situations, together the array of hypotheses cover a wide range of different situations. At every iteration the firm only considers the hypotheses specific to the current state and ignores the remaining hypotheses. This makes the firm capable of recognising different location patterns and applying the appropriate forecast.

Each hypothesis consists of two parts jointly forming a *condition/forecast* rule. The condition part specifies which situations trigger the forecast. And the forecast part contains the specific estimates used to make a prediction about the future location.

To describe the current state, we use a 13-bit descriptor. The descriptor $J_j$ summarises the location behaviour of firm $j$, e.g. the fourth bit in $J_j$ relays whether or not *firm $j$ is more than 0.6 standard deviations away from the mean ideal point of all consumers*. The ninth bit in $J_j$ relays whether or not *the position of firm $j$ along the agreement dimension (y-axis) is above the average of the last 16 periods*. Each of these bits take the value 1, if the state occurred, and takes the value 0, if the state is absent. The current state of firm $j$ could for instance be summarised by the following descriptor: `1110010001010`. We refer to the first 5 bits as the *fundamental bits*. They relay whether or not the distance from the firm to the mean ideal point of all consumers is greater than respectively 0.1, 0.25, 0.4, 0.6, or 1.2 standard deviations. These bits measure the degree to which the location of the firm is fundamentally different from the ideal point of all consumers. Bits 6-9 are the *tendency bits*. The bits 6-7 relay whether or not the position of the firm along the disagreement dimension (x-axis) is above the average of the last respectively 4 and 16 periods. And the bits 8-9 relay whether or not the position of the firm along the agreement dimension (y-axis) is above the average of the last respectively 4 and 16 periods. Thus these bits measure trends in the relocation pattern of the firm. Bits 10-11 are the *oscillation bits*. These bits use information about the position of the firm in the last four periods to determine whether or not there is oscillation along respectively the disagreement dimension (x-axis) and the agreement dimension (y-axis). More specifically it calculates the autocorrelation between consecutive periods and determines that oscillation takes place if the estimated first period lag operator is below the lower bound of the 85% confidence interval[^acf]. The last two bits are respectively always on and always off. These are experimental controls. By construction they contain no information about the current state, and thus they allow us to analyse to what degree firms act on useless information. 

[^acf]: With four periods the lower bound of the 85% confidence interval is $\underline{ci} = \frac{-1 - z \sqrt{N-k-1}}{N-k} \simeq -0.8151$, where the sample size is $N = 4$, the lag is $k=1$, and the test statistic is $z = 1.022$ (Meko 2015). 

Each *condition/forecast* rule attempts to recognise the current state. Therefore the condition consists of 13 corresponding positions each taking the value 1, 0, or #. The condition is met if the ones and zeros match the current state descriptor. The # is a wildcard character that matches either case, e.g. the condition `###1####0####` is satisfied, if the state described by the fourth bit occurred, and the state described by the ninth bit did not occur. In other words the condition will match any state, where *firm $j$ is more than 0.6 standard deviations away from the mean ideal point of all consumers, while its position along the agreement dimension (y-axis) is not above the average of the last 16 periods*. The condition `###1####0####` is not fulfilled if the current state descriptor is `1110010001010`, but the condition is satisfied, if the current state is `1111010001010`. More ones and zeros in the *condition/forecast* rule imply that the hypothesis is more specific, while a *condition/forecast* rule with many # will match more states and  thus represents a hypothesis that is more general.

All the *condition/forecast* rules that matches the current state of firm $j$, are said to be active. Among these active *condition/forecast* rules, the rule with the best accuracy is used to forecast the future location of firm $j$. In the case where several rules tie for the best accuracy, one of the rules is selected randomly and used to forecast. The accuracy of all active *condition/forecast* rules is updated once all the firms relocate and the actual location of each competing firm is revealed. The forecast error is the distance between the actual location of the firm and predicted location of the firm[^profiterror]. The accuracy measurement is based on the forecast error variance -- a lower forecast error variance imply better accuracy. The accuracy is updated using the inverse of the moving average of squared forecast errors (see details in appendix _[##]_). Over time the firm learns which hypothesis work well in a given situation. Thus the continuous updating of the accuracy of the *condition/forecast* rules facilitates learning. We will refer to this as *learning through experience*.[^learning]

[^profiterror]: Instead of basing the forecast error on location, the forecast error could be based on the difference between predicted profit (or market share) and the actual profit. While the latter approach is appealing because it aligns with the objective of the firm, we opt for the former approach in this paper. My guess is that the precision of hypotheses improves fastest when using the location forecast errors, meaning that less computational resources are needed to generate results.

[^learning]: *Learning through experience* is related to the concepts of *learning by using* (Rosenberg 1982) and *learning by doing*, although not the deductive part (Arrow 1971)*.

Using a *neural network* is an alternative to the *condition/forecast* approach by which firms could form predictions and learn from observations. The precision of forecasts generated by a neural network will be just as good, if not better, however the process by which a neural network generates predictions is a “black box” (Arthur 2014, chapter 3), i.e. we would not be able to see what type of information gave rise to specific predictions. Unlike the *condition/forecast* approach, where we can analyse the 13 positions in the condition to see if the *fundamental bits* or *trending bits* are most frequently activated and when the firm acts on useless information. 

The firm forecasts the future location of the competing firm $j$ using a linear forecasting model. 

$$\left( \begin{array}{*{20}{c}} {{x_{t + 1,j}}}\\ {{y_{t + 1,j}}} \end{array} \right) = \left( {\begin{array}{*{20}{c}} {{C_1}}\\ {{C_2}} \end{array}} \right) + \left( {\begin{array}{*{20}{c}} {{A_1}}&{{B_1}}\\ {{A_2}}&{{B_2}} \end{array}} \right)\left( {\begin{array}{*{20}{c}} {{x_{t,j}}}\\ {{y_{t,j}}} \end{array}} \right)$$

The six parameters of this model come from the most accurate active *condition/forecast* rule and take the form ($C_1$ $C_2$ $A_1$ $B_1$ $A_2$ $B_2$), e.g. the full *condition/forecast* rule might look like `###1#########` / (0.001 0 1.01 0 0 0.995). The rule  in this example states that if *firm $j$ is more than 0.6 standard deviations away from the mean ideal point of all consumers, then the predicted location along the x-axis is 1% further right and along the y-axis 0.5% less north relative to the current position, and then shifted an extra 0.001 standard deviation right along the x-axis.*

The *maxcov-inductor* firm makes predictions on the future location of all competing firms. Each competing firm $j$ has its own unique current state descriptor $J_j$. But the *maxcov-inductor* firm uses the same set of $M$ hypotheses for all competing firms. Thus we make the assumption that the *condition/forecast* rules are not tied to any particular competing firm. The hypotheses of the firm are not specific to the location behaviour of a particular competing firm, but generally applicable to any competing firms that exhibit a particular location behaviour[^altforcast]. 

[^altforcast]: Alternatively one could choose to model the firm such that it only makes predictions on the future location of neighbouring competing firms. The neighbouring competing firms will most likely have the greatest impact on the firm’s share of the market. Each competing firm $j$, which the firm currently shares a market boundary with, would have a current state descriptor $J_j$. The firm would assume that all other competing firms remained at their current location. Local predictions such as this would free up computational resources which instead could be used to allow each firm to hold hypothesis specific to a particular competing firm.

The *maxcov-inductor* firm is endowed a set of one hundred hypotheses (i.e. $M=100$). All but one hypothesis is randomly generated by the following procedure. Each position in the condition is randomly set to 1 or 0 both with probability 0.1, or set to # with probability 0.8. The forecasting parameters are drawn uniformly random. The forecast parameters $C_1$ and $C_2$ are drawn from a uniform distribution with range [-0.005 0.005], i.e. with a mean value of 0. The parameters $A_1$ and $B_2$ are drawn from the range [0.99 1.01]. And $A_2$ and $B_1$ are drawn from [-0.01 0.01]. The initial accuracy or forecast error variance of each *condition/forecast* rules is set to zero. The last hypothesis is the default or fallback option in case none of the other hypotheses match the state. This *condition/forecast* rule consists of only # so it matches any state and insures that the firm always is able to make a prediction. Each of the forecast parameters for this special rule is set to the average parameter values of the other $M-1$ *condition/forecast* rules. Because hypotheses are randomly drawn for each *maxcov-inductor* firm this implies heterogeneity in their decision process. *Maxcov-inductor* firms are heterogeneous in terms of their expectation model and knowledge, and not just in terms of the location they choose.

**Maxcov-Inductor-GA:**
A firm with the *maxcov-inductor-GA* decision rule behave as described above. The firm is still endowed with $M$ hypotheses that are randomly generated. But every $\varphi$ iteration the firm replaces the 20% least fit hypotheses. The fitness of the hypothesis is based on its accuracy and the specificity of the *condition/forecast* rule. The specificity of a *condition/forecast* rule is measured as the number of zeros and ones in the condition. Accounting for the specificity implies that rules with wider applicability (i.e. more #’s in the condition) are evaluated as more fit. Fit hypotheses are thus less likely to be discarded and more likely to form the basis of the new hypothesis. This implies that the model has a slight drift towards more general *condition/forecast* rules. The new hypotheses are created using a *genetic algorithm* (GA). This algorithm mimics an evolutionary process, i.e. hypotheses are developed from earlier hypotheses with randomly occurring mutations and by crossbreeding “parent” hypotheses. The genetic algorithm uses either *mutation* or *crossover* to create a new hypothesis. Appendix _[##]_ details the values, equations and the specific probabilities used. Each new hypothesis requires two parent hypotheses. The pair of parent hypotheses are drawn randomly and with equal probability from the set of hypotheses not discarded, i.e. from the 80% most fit hypotheses. 

With mutation the new hypothesis only inherits traits from the most fit parent. The method mutates the condition of the parent by randomly flipping the ones, zeros and #’s, and by randomly replacing or altering the forecast parameters. 

With crossover the new *condition/forecast* rule is a mix of both parents. The condition part is mixed by randomly selecting a donor parent for each of the 13 positions, e.g. the value of the first position might come from one parent, and three following positions might come from the other parent etc. This way the 13 positions are passed on from one of the two parents, and for each position the donor parent is randomly selected. Crossover of the forecast parameter values happens by either 1) component-wise crossover of each value, 2) using the weighted average of the parents or 3) randomly picking a parent that passes on all parameter values. The method used is randomly selected, and the three methods have equal probability of being selected. In the component-wise crossover the 6 parameter values  is mixed by randomly selecting a donor parent for each of the values. The weighted average of the parents parameter values uses the accuracy as weights.

To insure that the new hypotheses have a reasonable chance of being used, each new *condition/forecast* rule inherits the average accuracy of its parents. In the case where the parent rules have never matched a state -- and thus never been active -- the new hypothesis takes the median accuracy of all the non-discarded hypotheses. The firm always maintains the default *condition/forecast* rule that only consists of #’s. However its parameter values are updated such that these equal the weighted average of all new and non-discarded rules, where the accuracy is used as weight.

The process of discarding the poorly performing hypotheses and forming new hypotheses based on the fittest is another way in which the firm learns. The firm learns to make better predictions by gradually refining its hypotheses. I will refer to this as *learning through adaptation*. *Maxcov-inductor-GA* firms are heterogeneous, since their initial hypotheses are randomly drawn and because new hypotheses are formed based on the unique experiences of the firm.

### Results

In the following models there are two free parameters; the polarisation of subpopulations and the relative size. To parametrise our models we use the Monte Carlo parameterisation method. 

A *run* of the model still constitutes a stochastic process. However the process does not fulfil the Markov property, because of the *tendency bits* and *oscillation bits* in the current state descriptor $J_j$. These two sets of bits calculate respectively the moving average and the autocorrelation based on the recent location history of the firm. This implies that the future state of the process depends on past states of the process, which violates the Markov property. Additionally the process does not have stationary transition probabilities — even if we excluded the *tendency* and *oscillation bits* — and so does not constitute a time-homogenous Markov chain. Over time the firm continuously updates the accuracy of its hypotheses, and so the transition probability will depend on the experience of the firm. The first time the firm faces a given situation it might act in one way, while the firm might act differently, if it at a later point in time faced the exact same situation, because of the experience it had accumulated in between. In any model with a *maxcov-inductor* or *maxcov-inductor-GA* firm the underlying process of a *run* is stochastic, but we do not know much else about the process. We have no prior knowledge about convergence or steady states of the process. The literature does not yet provide answers on how to obtain representative estimates of our output variables when the process does not constitute a time-homogenous Markov chain. The tournament model by Fowler and Laver (2008) and the *Santa Fe Artificial Stock Market* by Arthur (2014, chapter 3) face similar issue. In both papers they nonetheless run several *repetitions* of the model for an extended number of *iterations*, discard *burn-in* iterations to remove the effects arising purely from the arbitrarily initial setup of the model, and estimate the output variables using the ensemble average, i.e. taking the average over all *repetitions*. This will also be the approach of this paper. We run several test repetitions of the most extreme cases, and visually inspect the trace plots for each output variable to determine when the process appears to have burnt off the effects of the initial position of firms and the initial learning by firms. The estimates of the output variables are calculated using the ensemble average once the process has burnt in.

**Maxcov-inductor:**

We start by comparing the results from the *maxcov-inductor* model with the results from the *maxcov* model to get a sense of how firms with an endogenous set of hypothesis form predictions about competing firms. And how the interaction of such firms influence the overall market and location behaviour of firms. We will use various examples to highlight the inner working of the decision rules.

![Mean eccentricity for *maxcov-inductor* model. Bands indicate +/- standard deviation.](Graphics/fig611a.png)

The *maxcov-inductor* and *maxcov* firms locate at similar distances to the ideal point of all consumers, for all degrees of polarisation between the subpopulation. With a high degree of polarisation, mean eccentricity increases as the number of firms in the market increase. Mean eccentricity tops with around seven firms in the market, and thereafter the mean distance of firms to the average ideal point of consumers remains at approximately 1.2 standard deviations. Although this was also observable in the *maxcov* model, it is slightly clearer in the *maxcov-inductor* model. Recall that *maxcov* firms tend to split into two crowds when the consumer distribution is bimodal and asymmetry. Each crowd locates close to the peak of a subpopulation, and thus far from the average ideal point of all consumers. Consequently the mean distance to the ideal point increases as the number of firms increase. The firms in each crowd compete with one another and compete less with firms in the other crowd. With less than eight firms in the market firms are unlikely to switch its location from one crowd to the other. As the number of firms increase beyond seven firms the probability that a firm switches crowds increases. The decrease in mean eccentricity is due to firms moving between the peaks of the subpopulation, and thus temporarily locating closer to the average ideal points of all consumers. This also seems to indicate a limit as to how many firms the crowds can sustain, before firms from different crowds start to compete more directly with one another.

![Trajectory plots for four firms in market with highly polarised subpopulation ($\mu=1.5$) and where left subpopulation is half as large as right subpopulations ($n_l/n_r = 1.5$). The black cross indicates the mean ideal point of all consumers. a) Location of four *maxcov*-firms after 155 iterations, where the lines show the location in the four preceding iterations. The two centre firms oscillate in opposite direction of each other. b) Location of four *maxcov—inductor* firms after 1007 iterations, where the lines show the location in the six preceding iterations. The three firms on the left form a triangular configuration.](Graphics/temp_maxcov_maxcov-inductor.png)

Although estimated mean eccentricity is quite similar in the *maxcov* and *maxcov-inductor* model, there are slight differences in how the firms choose to locate. This is perhaps best illustrated by looking at an example with four firms in a highly polarised market ($\mu=1.5$). When subpopulations are equally large ($n_l/n_r = 1$) then two peripheral firms locate close to the peaks of each subpopulation, while the two centre firms oscillate left and right in opposite direction of each other (see example of such oscillation in figure _[##a]_). When the left subpopulation is twice as large as the right, the left peripheral firm locates close the peak of its subpopulation, while the three remaining firms locate close the peak of the left subpopulation in a triangular configuration (see example in figure _[##b]_). And so, increasing the relative size of the left subpopulation shifts the locations of the centre firms further left. At some critical relative size the location of the centre firms comes sufficiently close to the peak of the left subpopulation, and the centre firms switch from oscillation left-right and into the triangular configuration. These location behaviours are observed in both the *maxcov* and *maxcov-inductor* model. However peripheral *maxcov-inductor* firms observe and predict the oscillation of the centre firms, and in response move closer to the centre. While centre firms shift further left to counterbalance the invasive peripheral firms, increasing the likelihood of the triangular configuration. This implies that the *maxcov* model requires more uneven subpopulations, before the switch from oscillation to triangular configuration takes place, compared to the *maxcov-inductor* model. In figure _[##]_, for each of the two models, we plot the trajectories of four firms with $\mu=1.5$ and $n_l/n_r = 1.5$. When the left subpopulation is half as large as the right, the centre firms in the *maxcov* model still exhibits oscillation, while three *maxcov-inductor* firms locate in the triangle configuration, with the left peripheral firm located close to the peak of the left subpopulation. We are observing how predictions lead to strategic considerations that ultimately influence the location of firms. Similar type of behaviour is also observed when the number of firms is not four. However these case are harder to describe, since there are not just two different location configurations, but often many different configurations. Predictions do not lead to new location configurations, but they affect the circumstance that lead to specific configuration.

![Effective number of firms (ENP) for *maxcov-inductor* model. Bands indicate +/- standard deviation.](Graphics/fig612a.png)

Comparing the *effective number of firms* (ENP) in the *maxcov-inductor* model to the *maxcov* model reveals similar ENP with less than eight firms in the market or with a medium degree of polarisation. However with more than seven firms in the market and with a low or high degree of polarisation the ENP is higher in the *maxcov-inductor* model. In these cases the fraction of consumers that each firm captures is more evenly distributed than in the *maxcov* model. 

![Trajectory plots for twelve firms. The top panels show the *maxcov* model, where dots indicate the location of the firm after 160 iterations. The bottom panels show the *maxcov-inductor* model, where dots indicate the location after 1010 iterations. The coloured lines show the location in the ten preceding iterations. The black lines are market boundaries after respectively 160 and 1010 iterations. of a) *Maxcov* firms in market with no polarisation ($\mu=0$, $n_r/n_l = 1$). Six firms have clustered at the centre of the market. b) *Maxcov* firms in market with high polarisation and uneven sized subpopulations ($\mu=1.5$, $n_r/n_l = 2$). Five firms have clustered near the peak of the left subpopulation. c) *Maxcov-inductor* firms in market with no polarisation ($\mu=0$, $n_r/n_l = 1$). No clustering of firms. d) *Maxcov-inductor* firms in market with high polarisation and uneven sized subpopulations ($\mu=1.5$, $n_r/n_l = 2$). No clustering of firms at iteration 1060. The red firm located at the peak of the left subpopulation previously paired with another firm, but only temporarily.](Graphics/temp_clustering.png)

In the maxcov model with many firms and a low degree of polarisation, a handful of firms will cluster together at the same location, as seen in figure _[##a]_. The clustered firms move in tandem. Each of the clustered firms assume that the other firms remain at their current position, and given this relocates to maximise its market share. However all the other firms in the cluster make the same decision, and they all end up at the same location. Once a cluster of firms is formed, it sometimes absorbs additional firms, but seldomly breaks apart. Similarly with a high degree of polarisation and uneven sized subpopulations, see figure _[##b]_. This reduces the ENP in the maxcov model with many firms, since the clustered firms compete for the same customers reducing their average market share. The clustering of maxcov firms in the models with low or high degrees of polarisation occurs, because there is a high concentration of consumers around only one or two points. Competition for these high density areas forces firms closer together and clusters emerge. In the maxcov-inductor model two firms may temporarily pair up, but any pairing of firms is short-lived and eventually breaks up, see figure _[##c]_ and _[##d]_. In turn, the long-run share of customers is more evenly distributed among firms and we observe a higher ENP. One or both of the paired firms will predict the future location of its competitor and distance itself to increase its share of the market. With a medium degree of polarisation, clustering and pairing of firms is short-lived in both models. There is a non-neglige number of consumers with ideal points in between the peaks of the distribution function. Consumers are not just concentrated around one or two points, but the density of consumers is spread over a larger area. Competition no longer forces firms together which eliminates the clustering of firms.

The difference in mean representation between the *maxcov* and *maxcov-inductor* model is minuscule. The mean representation plot for the *maxcov-inductor* model is therefore not included.

From the comparison above we learn that introducing firms with the ability to forecast the future location of competing firms has a limited effect on the how fare away firms locate from the average ideal point of all consumers. This distance is largely determined by the method with which the firm determines its optimal location, in this case the firm locates in the Delaunay triangle that encompasses most consumers. Forecast however play an important role in shaping the location behaviour of firms in cases with oscillation. We see that *maxcov-inductor* firms observe the oscillation of competing firms and uses this information to form its predictions. This precludes the most rudimentary oscillation patterns. Oscillation does not completely disappear with the introduction of *maxcov-inductor* firms. In this paper firms are only able to recognise periodic oscillation with period 2. That is firms only use information about the autocorrelation between two consecutive periods. If firms were also able to recognise oscillation with a higher period, it would likely reduce oscillation even further. Furthermore we learn that several *maxcov-inductor* firms are unlikely to cluster at the same location. Two firms may pair up, but the this is often short-lived. One or both firms will anticipate the future movement of the other firm, and realise that it can increase its share of the market by distancing itself.

**Maxcov-inductor-GA:**

We extend the decision rule further. *Maxcov-inductor-GA* firms locate in the Delaunay triangle that maximises its share. The firms use inductive reasoning to forecast the future location of competing firms. And the firms gradually discard poorly performing hypotheses, and form new hypotheses using a Generic Algorithm. Thus hypotheses are endogenously formed.

![Mean eccentricity for *maxcov-inductor-GA* model. Bands indicate +/- standard deviation.](Graphics/fig621a.png)

Once again we see very little change in the mean distance to the ideal point of all consumers with a low and medium degree of polarisation. *Maxcov-inductor-GA* firms locate in the Delaunay triangle that maximises its share. This is the decisive factor in determining the mean distance to the ideal point. With a high degree of polarisation between the two subpopulations mean eccentricity is significantly lower in a market with five firms compared with the *maxcov-inductor* model.

![Trajectory plot for five *maxcov-inductor-GA* firms at different iteration intervals ($\mu=1.3$ and $n_l/n_r=1.5$). The dots indicate the location after respective 270, 310 and 2500 iterations and the lines indicate the location in preceding iterations. The black cross indicates the average ideal point of all consumers. a) Three-two split. b) Transition interval. c) Four-one split.](Graphics/temp_fig6m_miga.png)

As mentioned earlier firms tend to split into two crowds when the there is a high degree of polarisation between the mean ideal points of the two subpopulations. With five firms and the degree of polarisation close to 1.5, the firms tend to locate in a three-two split. When the degree of polarisation is close to 1 and the distribution is sufficiently asymmetric ($n_l/n_r$ not too close to 1), then the split tends to be four-one. This is the case in both the *maxcov-inductor* and *maxcov-inductor-GA* model. However the *maxcov-inductor-GA* model requires less polarisation among the subpopulations for the four-one split to occur. In figure _[##]_ we plot the location of five *maxcov-inductor-GA* firms for $mu = 1.3$ and $n_l/n_r = 1.5$. The firms quickly converge to the three-two split, but this location configuration is not sustained, and after 270 iterations the firms transition into a four-one split. For comparison we re-execute the model with the same initial positions and the same set of endowed condition/forecast rules, but where firms use the *maxcov-inductor* decision rule instead of *maxcov-inductor-GA*. The *maxcov-inductor* firms maintain the three-two split also after 270 iterations and locate as in figure _[##a]_. This explains why we observe a lower mean eccentricity in the *maxcov-inductor-GA* model with five firms compared to the *maxcov-inductor* model. With a four-one split the firms locate closer to the average ideal point of consumers than firms that locate in a three-two split.

![Average forecast error variance of all the activated condition/forecast rules of the firms. a) Five maxcov-inductor-GA firms. Transition interval highlighted. Every 50th iteration the firms discard and replaces the 20% poorest performing condition/forecast rules. The transition interval is highlighted. b) Five maxcov-inductor firms with the same initial position and set of endowed condition/forecast rules.](Graphics/temp_fig6a.png)

Furthermore we can compare the accuracy of the two cases. The *maxcov-inductor-GA* firms replaces the 20% worst performing hypotheses every 50th iteration, while the *maxcov-inductor* firm uses the same set of $M$ hypotheses indefinitely. In figure _[##]_ we plot the average forecast error variance of all the condition/forecast rules for each the firm at each iteration. We disregard condition/forecast rules that have a forecast error variance of zero, and thus have not previously been active. A low forecast error variance indicates that the hypothesis provided accurate predictions in the past. We focus on the first 500 iterations. For the first 50 iterations the forecast error variance is the same in both cases, since the firms make predictions using their endowed set of hypotheses. In the *maxcov* model the average forecast error variance increases steadily, but at a steadily decreasing rate, as firms learn which hypothesis provide the most accurate predictions. Firms learn through experience. This is also the case in the *maxcov-inductor-GA* model, but in additions firms learn through adaption. Discarding poorly performing hypotheses and replacing them with new hypotheses that are based on the best performing hypotheses significantly increases the accuracy. After 270 iterations the firms have discovered a sufficiently accurate location pattern of their competing firms, allowing the firms to move from the three-two split to the four-one split. Notice that the three firms that move furthest in the transition interval are not simultaneously experiencing an increase in their average forecast error variance. The predictions they make during this transition are at least as precise as previous predictions. Thus the transition cannot be attributed to synchronised and systematic break down in forecasts, but rather the transition is the result of a deliberate and calculated response to the predicted future locations of competing firms. These are strategic moves. While the two other firms experience an increasing average forecast error variance during the transition, they quickly adapt to the environmental change. And we see that shortly after the transition the firms are quite similar in terms of the accuracy of their hypotheses.

![Effective number of firms (ENP) for maxcov-inductor-GA model. Bands indicate +/- standard deviation.](Graphics/fig622a.png)

The effective number of firms (ENP) is largely unaffected by the extension of the decision rule. In the model with five firms, where the four-one split is more likely, results in a lower ENP, since the single firm captures the entire right side of the market for itself. Examining the market share of each firm over time reveals differences in terms of the long-run competitive advantage one firm may have over its competitors. This is best illustrated in a market with three firms, by comparing the *maxcov*, the *maxcov-inductor* and the *maxcov-inductor-GA* model. For each model we plot the market share across time in a market with a highly polarised and uneven sized subpopulations ($\mu=1.5$ and $n_l/n_r = 2$). See figure _[##]_. 

![Share of market with three firms, $\mu = 1.5$ and $n_l/n_r = 2$. Red line is the firm located at the right peak. While the blue and green line are the two firms located close to the left peak. a) *Maxcov* model. b) *Maxcov-inductor* model. c) *Maxcov-inductor-GA* model.](Graphics/temp_fig5s.png)

In the *maxcov* model, after the initial burn-in periods, the location of the firms lock in. One firm locates close the right peak of the distribution function, while the two other firms locate around the left peak. The location of the right firm is consistent across different initial locations, while the location configuration, which the two firms on the left lock into vary depending on the initial position of firms. Additionally the two firms on the left often oscillate. The firm on the right captures 1/3 of the market. One of the firms on the left captures a slightly larger share, and the other a slightly lower share. While our estimate of the ENP is independent of the initial position of firms, the initial position determines how each firm ranks in term of market share. It is evident from figure _[##a]_, that certain initial positions gives one firm a clear long-run competitive advantage over its competitors in the *maxcov* model. 

In the *maxcov-inductor* model firms predict the future location of competing firms, using the hypotheses that match the current state and proved most accurate in the past. After several dozen burn-in iterations, the firm on the right, once again, locates close the right peak and captures 1/3 of the market. The two firms on the left will not immediately lock in, but switch between different location configurations. The ranking in terms of market share changes when the two firms switch between configurations[^locconfig]. The firms do not immediately lock in, since firms are able to predict and respond to the future location of competing firms, such as oscillation. Over time the firms learn which of their hypotheses give the most reliable predictions. And the firm often ends up using a limited set of hypotheses, see figure _[##]_. The two firms on the left lock into a specific configuration or a specific few configurations, once all firms converge to using a limited set of hypotheses. Once the firms lock in, so does their share of the market, as seen in figure _[##b]_. The initial position of the firm does not by itself create a long-run competitive advantage in the *maxcov-inductor* model. Instead it is a combination of initial position and the set of hypotheses which the firms is endowed with, that can give the firm a long-run competitive advantage. While the firm is able to update the accuracy of each hypothesis, the conditions and forecast values remain fixed. If a firm is endowed with a set of poorly performing hypotheses, then the firm is unlikely to capture more than 1/3 of the market in the long-run.

[^locconfig]: These configurations are the same as those that arose, when using different initial positions, in the *maxcov* model.

![The condition/forecast rule used at each iteration by each of the three maxcov-inductor firms to forecast the future location of competing firms. After approximately 200 iterations all firms use a limited set of condition/forecast rules. After approximately 400 iterations the set does not change.](Graphics/fig5cf_mi.png)

In the *maxcov-inductor-GA* model, where firms gradually form new hypotheses, the two firms on the left never lock in, but continue to switch between the different location configurations. _[LOCATION CONFIGURATIONS.]_ The firms may temporarily get stuck in a specific configurations, where all firms use a limit set of hypotheses, but eventually the firms form new hypotheses that change how the firms locate. The set of hypotheses which the firm is endowed with does not give the firm a long-run competitive advantage over its competitors. Instead there will be prolonged periods where one of the two firms on the left capture more than 1/3 of the market, followed by periods where the reverse is true. This highlights how one firm may use tactics that are superior to its competitors and how competing firms gradually learn and develop counteracting responses. The *maxcov-inductor-GA* firm continuously adapts to changes in its environment. This type of behaviour is not unique to a market with three firms and highly polarised and uneven sized subpopulations. The same is true with a different number of firms in the market and different parameter values[^whythree]. 

[^whythree]: The polarised and uneven market with three firms contains a lot of different location configurations while the low number of firms makes it easier to describe. And so we used this for the basis of the example. With two or four firms in the market there are only a few location configurations, all of which are fairly stable, and so the described behaviour is less pronounced since there is less changes to the environment of the firm.

![Mean representation for *maxcov-inductor-GA model*.](Graphics/fig623a.png)

The mean representation in the *maxcov-inductor-GA* model is almost identical to the *maxcov* and *maxcov-inductor* model, as seen in figure _[##]_.


# 5. CONCLUSION

This paper set out to reintroduce foresight and thus strategic consideration into the competitive location model. Something that has thus far been missing from the agent-based models. The paper argues why it is unreasonable to assume that firms use *deductive reasoning* to deduce their optimal location. Instead we argue that firms derive principles and conclusions from observations and viewing conclusions as probable, rather than certain, i.e. firms use *inductive reasoning*. The firms possess numerous hypotheses, each relevant to specific set of situations. Hypotheses are updated in response to new information or observations that falsifies the currently held hypotheses. The firms predict the future location of competing firms, using the hypothesis viewed as most probable in the given situation. When a firm chooses its own location it takes the future location of competing firms into account. The firm acts strategically, and is no longer oblivious to the simultaneous relocation of competing firms.

The model in this paper encompasses the “natural” setting of competitive product differentiation or location differentiation. That is a setting with few firms in the market not necessarily restricted to a single dimension and where the distribution of consumer preferences might be asymmetric and multimodal. The conclusions from the previous literature on competitive location models mainly concern one dimensional markets or duopolies. Yet in most markets more than two firms compete, and they often choose along several product characteristics not just one. While it is convenient to assume that consumers are uniformly distributed, this assumption is highly unrealistic. The case where the preference of all consumers is uncorrelated must be considered a special case. More generally consumers are likely to lump together in subpopulations. Possibly due to social interactions among consumers, such as desire for social conformity or other network effects. These subpopulations then give rise to an aggregated distribution of consumer preferences that is multimodal and quite possibly asymmetric.

Predictions by themselves have a limited effect on the overall location pattern of firms. We do not observe locations that are fundamentally different when using decision rules with foresight. The main driver in determining the location patterns is the method used by the firms to determine the optimal location given its predictions. In this paper the firms located in the Delaunay triangle with most consumers. While predictions do not affect the overall location pattern, they do influence specific location behaviours such as oscillation, clustering of firms, and it changes the probability of certain location patterns. In a market with many firms predictions lead the firms to capture a more even share of the market, namely because any pairing of firms is short lived. This is somewhat surprising given the fact that we introduce additional sources of heterogeneity for firms. In the models with foresight firms are also heterogeneous in terms of their expectation model and knowledge.

In the paper we also consider the social welfare of consumers. The interacting effect of firms competing for consumers seems to results in locations that are more or less on par with the social optimal location (except in the cases with less than four *hunter* firms and a bimodal distribution). This is a quite striking result considering the conclusions of earlier papers. In the line market *the principle of local clustering* lead firms to locate far from the social optimal locations. And in the two-dimensional Hotelling model with a uniform distribution of consumers, the two firms locate at the centre, thus also far from the social optimum. The main reason that competition leads to more or less socially optimal locations is the paper is due to the assumed distribution function. We assume that each subpopulations follow a bivariate normal distribution with standard deviation (0.5, 0.5). This gives a high concentration of consumers around the peaks of the aggregated distribution function. Increasing the standard deviations would decrease the concentration of consumers around the peaks, and we would most likely observe a decrease in the average utility of consumers that would be more in line with previous papers. 

The paper is a first attempt at laying down the foundation for a competitive location model with foresight. There still ample room for improvement and many possible extensions. An obvious extension is entry and exit of firms such that the number of firms is endogenously determined. Similarly incorporating price competition into the model seems to be a natural next step. The lack of methods for finding the optimal location meant that in all the *maxcov* decision rules used a rough approximation. Developing new techniques for finding the optimal location of new entrants in the market, as well as the optimal location of existing firms, would be of benefit to the models in this paper, and the field in general.

# A. APPENDIX 


## A.1 Model overview

**Homogenous firms:**

* **All-sticker:** non-ergodic deterministic time-homogenous Markov chain. [The firms never move, so the process “converges” to a single state, which “depends”/is the initial position of the firm, thus the “process is non-ergodic.]
* **All-hunter:** ergodic stochastic time-homogenous Markov chain. [When market share of a hunter firm decreases the firm turns around and heads in a randomly drawn opposite direction. This random component, makes the underlying process ergodic. In the model with a symmetric distribution of consumers the *time average* provide a representative estimate of $\psi$, i.e. the only free parameter in the model is the number of firms, N. While this is not the case in the model with an asymmetric distribution of consumers, thus the *ensemble average* is used. Several R-hat statistics are above 1.05 even when executing the test repetitions with 20.000 iterations.]
* **All-aggregator:** non-ergodic deterministic time-homogenous Markov chain. [Each repetition is an implementation of the Lloyd-algorithm, which always converges to a single state. However the state is not unique, a different initial position of the firms might result in a different CVT. Hence the process is non-ergodic.]
* **All-maxcov:** deterministic time-homogenous Markov chain. ergodic?? single state or oscillates?

**Heterogeneous firms:**

* **Maxcov-inductor:** Does not fulfil Markov property. In the *trending bits* we use the moving average, thus the probability of the future state will depend on past states, and only the current state. Random set of hypothesis (however this is not a random component in the process, but only affects the initial state space distribution $\pi_0$).
* **Maxcov-inductor-GA:** Does not fulfil Markov property. Random component (when forming new hypothesis).

## A.2 Maxcov vs maxcovrnd

![Maxcov vs maxcovrnd in market with symmetric and unimodal distribution of consumers ($\mu = 0$ and $n_l/n_r = 1$).](Graphics/temp_maxcovrnd_sym.png)

![Maxcov vs maxcovrnd in market with asymmetric and bimodal distribution of consumers ($\mu \in [0,1.5]$ and $n_l/n_r \in [1,2]$).](Graphics/temp_maxcovrnd_asym.png)

## A.2 Maxcov-inductor mean representation

![Mean representation for maxcov-inductor model.](Graphics/fig613a.png)

## A.3 Hypothesis & GA

The number of hypotheses is set to $M=100$. 

-----

To **update the accuracy** of a *condition/forecast* rule we use the inverse of the moving average of squared forecast errors. The accuracy of firm $i$ using hypothesis $m$ at iteration $t$ is:

$$e^2_{t,i,m} = \alpha_a e^2_{t-1,i,m} + (1-\alpha_a) \left( X_{t+1,j} - E_{t,i,m} [X_{t+1,j}] \right)^2, \quad \forall j \ne i$$

where $\alpha_a$ is the memory parameter and $X_{t+1,j}$ is the future location of competing firm $j$. The memory parameter is set to $\alpha_a = 1-1/75 = 74/75$.

-----

**Fitness measure** of rule $m$ at iteration $t$ for firm $i$ is:

$$f_{t,i,m} = M - e^2_{t,i,m} - Cs_m$$

Where $M$ is the number of *condition/forecast* held by firm $i$, since this is constant and identical across firms the term can be left out. $e^2_{t,i,m}$ is the forecast error variance, and $C$ is the cost levied on the specificity. And $s_m$ is the specificity of rule $m$ calculated as the number of ones and zeros in the condition part of the rule (i.e. all the # are not counted).

-----

It is randomly decided if crossover or mutation is used to create the new condition/forecast rule. The crossover method is used with probability $p$, and mutation method with probability $1-p$. This paper uses $p = 0.3$.

**Mutation method:**
Each position in the condition is mutated or flipped with probability 0.03. The probability that 0 or 1 is flipped to # is 2/3. The probability that 0 is flipped to 1 and visa versa is 1/3. The probability that # is flipped to 1 or 0 is 1/3 respectively, with the remaining 1/3 probability that # is not flipped. With these flip-probabilities on average maintain the number of 1, 0 and # in the rule. Each forecast parameter value is either replaced or changed, each with probability 0.2. Leaving 0.6 probability that the parameter value is unchanged. If replaced then the new parameter value is drawn randomly from the same ranges as the initial parameter values (see _[page ##]_). If changed then the new parameter values altered with a random amount in the range plus/minus 0.5% of the initial parameter range.