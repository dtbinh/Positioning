The literature on spatial competition began with Hotelling's (1929) paper. Hotelling proposes a line market where consumers are uniformly distributed along the line and firms produce homogenous goods. Consumers inelastically demand one unit from the firm with the lowest price. The price is composed of the *mill price* and *transportation cost*. Each firm charges a *mill price*, ie. the price for one unit purchased at the doorsteps of the firm. And customers bear a cost by going to the firm to shop. This *transport cost* is linear in the distance between the customer and the firm. Two firms decide where to locate and which *mill price* to charge. Firms first simultaneously choose their location, and thereafter simultaneously decide on their prices. There are two opposing forces that come into play; If the firm locates close to its competitor, it will attract more consumers. Meanwhile locating closer also lead to more fierce price competition from its competitor.

If *mill prices* are fixed and equal then there is no price competition and both firms locate at the centre of the market and split the market equally. The agglomeration of firms has been coined *the principle of minimal differentiation*[^1]. The average distance travelled by consumers is one-fourth the length of the line. This is socially suboptimal. The social optimal location is where the market is split in two halves, with a firm located at the centre in each of these halves. This reduces the average distance to one-eighth of the length of the line. 

[^1]: *The principle of minimal differentiation* was coined by Boulding (1955).

An error lead Hotelling to conclude that the model with price competition would also exhibit *the principle of minimal differentiation*. But when two firms are located in close proximity near the centre, price competition drives down prices to a level where it is no longer optimal for firms to located in the middle half of the line. The paper by d'Aspremont, Gabszewicz, and Thisse (1979) shows this and that no equilibrium exists in the model laid out by Hotelling. Instead they modify *transportation cost* to be quadratic in the distance between the customer and the firm, rather than linear. With this modification a unique equilibrium exist, but where firms locate at either ends of the line, ie. *maximal differentiation*. This shows how the *the principle of minimal differentiation* breaks down when price competition is introduced. This is just one example of a non-robust conclusion.

The general result from the 85 years of research since Hotelling’s paper is that conclusions and equilibrium are non-robust across alternative model specifications. Researchers have generalised the model, but most of the results are falsified when assumptions are modified. Even minor modification may remove any equilibrium constellations. _[One might then ask, why the model appeals to researchers and why the continued interest in the Hotelling model? (Paradigm shift? Lack of alternative model/explanation?)]_

Below I will review some of the literature on the Hoteling model and more generally spatial competition models. I will present the reader with papers that relax the assumptions and generalise the Hotelling model. Biscaia and Mota (2013) find 352 published journal articles since 1979 that reference ‘Hotelling’ or ‘spatial competition’. The sheer volume of papers on the topic makes it a colossal task to provide an exhaustive review. This literature review is not exhaustive, but selective and focused on the papers deemed relevant for this particular paper. The following set of papers provide an exhaustive review of the topic; The early developments and historical development of the spatial competition literature is reviewed by Eiselt and Marianov (2011, chapter 1) and Smith, Laporte, and Harper (2009). Biscaia and Mota (2013) contain a bibliometric analysis of the literature. Eiselt (2011) provide a reissue of Hotelling’s original paper with comments and references to later contributions. Graitson (1982), Brenner (2001), Eiselt, Laporte and Thisse (1993) provide literature reviews focused on the Hotelling model. While Kilkenny and Thisse (1999) and ReVelle and Eiselt (2005) give a more general review of spatial competition models. Daskin (2008) provide a review of discrete spatial competition models. Sequential location models are reviewed by Eiselt and  Laporte (1996) and Kress and Pesch (2012). And the review by Plastria (2001) focuses on the optimisation approaches to competitive location models.

## Space and number of firms

Eaton and Lipsey (1975) considers both the line market and two-dimensional space. They assume that firms charge a fixed price, and they investigate the equilibrium with _N_ number of exogenous firms in the market. 

Eaton and Lipsey (1975) prove analytically that no equilibrium solution exists when three firms have similar price. In the line market the two firms at each perimeter will move towards the centre of the line, reducing the market of the third firm. Eventually this forces the firm at the centre to leap-frog to the outside. This process continues with the two outer firms again moving towards the centre of the line. This has been referred to as the *dancing equilibria* although no equilibrium exist (Eiselt, 2011). In the line market with four firms, two firms will locate at one-fourth the length, and two firms will locate a three-fourths the length of the line. Similarly in the case of five firms, two firms are located at one-fifth the length, two at four-fifths the length, and the fifth firm will locate at the centre. The equilibrium ceases to be unique for six or more firms, instead it is a range of equilibria. If there is an odd number of firms, then one firm will be located at the centre of the line. The firms on the perimeters are paired. While the remaining interior firms may be paired, or may be separated by some distance. However no firm will have a total market area less than the *half-market* of any firm. The *half-market* refers to the two market areas on either side of the firm. Eaton and Lipsey (1975) conjecture that the *principle of minimum differentiation* should perhaps be replaced by *the principle of local clustering*, since pairs of firms choose to locate in close proximity to one another. _[Eaton and Lipsey (1975) also consider multimodal and asymmetric distributions of consumers along the line. Here they prove that an equilibrium requires that the number of firms in the market does not exceed twice the number of modes in the consumer density function. Ie. if the distribution of consumers is bimodal (two modes), then no equilibrium exists with four or more firms in the market.]_ 

The results above from Eaton and Lipsey (1975) rely on the assumption that firms behave without foresight -- an assumption they call *zero conjectural variance*. Eaton and Lipsey (1975) drop this assumption to analyse how firms with foresight choose to locate. For this they assume firms adopt a *minimax strategy* where firms anticipate the entry of a new firm into the market. This leads firms to minimise their largest *half-market*. When a firm locates at the centre of its own market, rather than at the perimeters, it minimises the exposure to new firms entering the market. With this assumption firms never locate in pairs as described above. Instead, for any number of firms, there exists a unique equilibrium where firms are evenly spaced along the line. These equilibria are socially optimal as they minimise the average distance to consumers. *The principle of local clustering* does not hold when firms use a *minimax strategy*.

Shaked (1975) prove analytically that no equilibrium exists for three firms locating in the plane. Eaton and Lipsey (1975, p. 40) note that it is not obvious how three or more firms will choose to locate in two-dimensional space, and write that *"using conventional analytical techniques the problem is very complex, perhaps intractable"*. Instead they use simulation techniques and once again assume that firms behave without foresight. In their simulation consumers are uniformly distributed on a disc, rather than a plane. They show that a local equilibrium exists for the firm, where all firms are evenly spaced along a circle with the same centre as the disc, and with a radius that is less than the radius of the disc. However this is not a global equilibrium for the firm, and the circular configuration immediately breaks up, since the firm will choose to pair up with one of its neighbours rather than remain fixed on the circle. The same is true for more than 8 firms in the market, where one firm is located at the centre, and the remaining firms are evenly spaced in a circular configuration. The firm at the centre is in a global equilibrium, but the firms on the circle are only in a local equilibrium. In addition they show that no equilibrium exists for firms located in a hexagonal pattern, square pattern or rectangular pattern. The firms on the perimeter of the market will pair up with neighbours, breaking the pattern. In sum they suspect that no equilibrium solution exists for three or more firms in two-dimensional space. This is still an open question.

### Location problems

The Hotelling model belongs to a wider set of *competitive location models*, which again falls into the more general realm of *location problems*. The difficulty of finding optimal solutions is not restricted to the Hotelling model. It shows up in many other location problems -- even in problems without any kind of competition among the firms or agents. This subsection looks more generally at location problems and optimal solution.

The location problem aimed at finding the location of the firm that minimises the sum of distances to all its consumers is called the *minisum problem*. The minisum problem on the continuous plane is known as *the Weber problem* (Eiselt and Marianov, 2011 chapter 1). And the *multistore Weber problem* is when the firm has multiple facilities and the aim is to find the locations on the plane that minimise the sum of distances from each facility to the consumers (Eiselt and Marianov, 2011 chapter 15). The *multistore Weber problem* is difficult since it consists of two subproblems -- an allocation problem and a location problem -- that have to be solved simultaneously. It has been proven that the computational difficulty in solving this problem is *NP-hard*[^NP-hard], and thus heuristic approaches are required for large problems (Eiselt and Marianov, 2011, p. 336). Heuristic methods find good solutions, but do not guarantee that the solution is optimal.

A relative to the *minisum problem* is the *minimax problem*. In this problem the objective is to minimise the longest distance between the firm and its consumers. On the continuous plane this problem is known as the *continuous 1-centre*. And more generally, when the firm has multiple facilities, the *continuous p-centre*. This problem minimises the longest distance between _p_ facilities and their consumers (Eiselt and Marianov, 2011 chapter 4). These problems resemble *set covering problems*. More specifically, when there is positive demand everywhere, then the *continuous p-centre* is equivalent to the problem of covering an area with _p_ circles with the minimum possible radius, also known as *circle covering*. Masuyama, Ibaraki and Hasegawa (1981) show that the problem is NP-Complete[^NP-complete].

Thus finding the optimal solution is difficult even when disregarding the competitive aspects of location where firms interact with one another.

[^NP-hard]: In the field of computational complexity theory a distinction is made between problems that can be solved in *polynomial time*, and those problems that cannot. A problem is said to be “easy” and “feasible” when it can be solved in polynomial time. A solution to an *NP-hard* problem may not be verifiable in polynomial time. *NP-hard* problems are at least as difficult as *NP problems*, and a solution to an *NP problem* can be verified in polynomial time. (Ahuja, Magnanti and Orlin, 1988, Appendix B).

[^NP-complete]: An NP-complete problem is both an *NP problem* and *NP-hard problem*. That is the solution can be verified in polynomial time, but no efficient method exists that can find the solution to these problems.

#### Voronoi diagram

A *Voronoi diagram* or *Voronoi tessellation* is a geometrical constructions used to characterise allocation and studied for more than 175 years in different fields (Eiselt and Marianov, 2011 chapter 19). This subsection will review properties of Voronoi diagrams, and concepts that have arisen from the research on Voronoi diagrams. A Voronoi diagram consists of several Voronoi set. Each Voronoi set has an associated *seed*, and each set contains all the points that are closer to the associated *seed* than any of the other *seeds*. A Voronoi diagram can be constructed from the location of firms and their respective market areas. For instance in the fixed-price Hotelling model consumers shop at the nearest firm. Thus the *seeds* correspond to the location of firms. And the Voronoi set describes the market area of the firm and the set contains all of the customers that are located closer to the firm than any of the other firms. _[The diagram can be constructed with different distance metrics, each resulting in a different Voronoi diagram.]_

The mean point of a Voronoi set is referred to as its *centroid*. This point minimises the sum of distances to all points within the Voronoi set. A firm located at the *centroid* of its market area constitutes a local socially optimal location. The *centroidal Voronoi tessellation* (CVT) is a special case of the Voronoi diagram where all *seeds* are located at the centroid of their set. If all firms locate at their respective *centroid* it creates a *centroidal Voronoi tessellation*. This is a global socially optimal solution, since it minimises the average distance between consumers and firms. It leads to optimal “representation” or optimal market allocation (Laver and Sergenti, 2011). Any *centroidal Voronoi tessellations* is optimal, but not necessarily unique. Given for instance 2 firms in a square space there are several CVTs; the firms could locate left-right splitting the market in half vertically, the firms could locate up-down such that they split the market in half horizontally, and so on. In each case the overall distance to firms is minimised and constitutes an optimum. The Lloyd’s algorithm generates a *centroidal Voronoi tessellation* from any generic Voronoi diagram. At every iteration, the algorithm moves the *seeds* to the centroid of their current Voronoi set. Using this iterative process any Voronoi diagram converges to a *centroidal Voronoi tessellation*. 

The dual of the Voronoi diagram is the *Delaunay tessellation* (Eiselt and Marianov, 2011 chapter 19). The *Delaunay tessellation* is a network that links *seeds* with adjacent Voronoi sets and where the length of the link is the distance between the *seeds*. Reformulated in terms of firm location, the network links the firms that share a market boundary (ie. direct competitors), and the length of each link is the distance between the two firms. Eg. In the line market with three firms, the Delaunay tessellation will not link the two firms on the perimeters together, since they do not share a market boundary, however both these firms are linked to the firm in the middle.

In a bounded two-dimensional space, each Voronoi set creates a polygon[^poly]. The number of sides, the area and the perimeter of the polygon are measures that can be used to characterise the Voronoi set (Okabe, et. al. 2009). In terms of firm location these three measures would be the number of direct competitors, the market size, and length of the market boundaries. _[The latter is a proxy for the surface tension/energy of the market. The points on the market boundary exhibits higher energy than interior points.]_ The properties of the polygon provide descriptive statistics on each firm. However they contain less information on the intrinsic interaction between firms that is an integral part of competition. The network formed by *Delaunay tessellation* provides insights on interaction. The number of direct competitors can also be obtained from the network by counting the number of links emanating from a firm. But more importantly the links tell which specific firms are in direct competition with one-another, and in a dynamic setting they tell how the competitive setting changes over time. As earlier noted, Eaton and Lipsey (1975) find that the hexagonal, square and rectangular pattern break up because firms on the perimeter will pair up with neighbours. The *Delaunay tessellation* provides an easy method to analyse such behaviour and a method to generalise the findings. _[The *Delaunay tessellation* seem to be under-explored in the contemporary literature on competitive location of firms.]_

[^poly]: Strictly speaking, the Voronoi set is only a polygon for certain distance metrics. Only distance metrics where the boundaries of Voronoi sets are line segments will lead to polygons. Commonly used distance metrics -- such as *Manhattan*, *Euclidean* and *Chebyshev* -- all fulfil this requirement (Eiselt and Marianov, 2011, chapter 19).

Another thing that has arisen from Voronoi diagrams is the *Voronoi game*. This competitive location model shares features with the Hotelling model. In the Voronoi game two firms place _n_ number of facilities each and consumers shop at the nearest facility. The game is sequential so firms take turns and place each facility. The game ends after _2n_ turns when both firms have placed all their facilities, and the winner is the firm with the most consumers. In the continuous line market the follower has winning strategy that captures $frac{1}{2+\epsilon}$ of the market area, however the leader has a strategy that can make $\epsilon$ arbitrarily small (Ahm, Cheng and Cheong 2001). The two-dimensional Voronoi game is significantly more difficult to solve. In a one-round version of the Voronoi game where each firm place all its _n_ facilities in turn on a continuous square area, the follower still has a winning strategy, but the leader cannot make $\epsilon$ arbitrarily small (Eiselt and Marianov 2011, chapter 9). If instead consumers are distributed over a rectangular area that is sufficiently oblong, then the leader has a winning strategy (Fekete and Meijer 2005). Fekete and Meijer (2005) furthermore show that the follower’s problem is NP-hard in the two-dimensional one-round game.

## Space – Hinterlands, vertical differentiation and networks

The choice of space influences results. As seen above moving from one-dimensional space to two-dimensional space changes the equilibrium, and sometimes removes the equilibrium altogether. Similarly the shape of the space (square, disc, rectangular) and whether the space is bounded or unbounded affects the results. Certain combinations of shape and boundary enable *hinterlands*, that is remote areas or sparsely populated areas. Competing firms will find it less attractive to locate in these regions. As a result the papers that consider spaces without natural hinterlands -- such as the one-dimensional circular market -- find that firms are more evenly spread out (Eaton and Lipsey 1975, Salop 1979).

Although the models are described in terms of geographical location, they are also applicable when studying product differentiation. Ie. Manufactures compete with one another when they choose product characteristics such as size, colour, and shape. In terms of geographical location the ideal point of the consumers is his or her location. In terms of product differentiation the ideal point is the consumer’s preferred product characteristics. The ideal points are distributed over the space, and so the consumers have heterogeneous preferences regarding products or firms. The models discussed so far strictly consider *horizontal product differentiation*. Thus even when firms charge the same price, firms are able to achieve some positive demand, through differentiation. There are niches that guarantee the firm a positive profit. This is not the case with *vertical product differentiation*, such as product quality where the preferences of consumers are homogenous, ie. all consumers prefer high quality products to low quality products. If firms charge the same price, then the firm with the highest product quality will capture the entire market. No niches exists. The two-dimensional Hotelling model assume *horizontal production differentiation* along both dimensions. An alternative model is the Launhardt model (Ferreia and Thisse 1996). The model includes both *horizontal* and *vertical product differentiation*. It can be seen as an extension of the Hotelling model[^Launhardt] in that firms choose location, but firms have different delivery prices. The delivery prices is an easy way to incorporate *vertical product differentiation* into the model The delivery price is part of the *transportation cost* paid by consumers. Consumers still shop at firm with the lowest prices (*mill price* and *transportation costs*), thus all consumers prefer low delivery prices over high delivery prices. The Launhardt model is in a sense two dimensional. The location dimension assumes *horizontal product differentiation*, while the delivery price dimension assumes *vertical product differentiation*.

[^Launhardt]: Although the Launhardt model can be seen as an extension of the Hotelling, the paper by Launhardt was published 44 years before Hotelling published his paper.

Another string of papers part with real space, and considers firm location or product differentiation in discrete space, such as on networks. Daskin (2008) provides a review of discrete spatial competition models.

## Price competition

_[Although this paper does not consider price competition I would no the less like to highlight a couple of papers that may indicate how the results in this paper might change if price competition was included ...]_
_[Irmen and Thisse (1998) : multiple dimensions. Equilibrium with maximum differentiation along one dimension (the dominant), and minimum differentiation along all others.]_
_[Liu and Shuai (2012) : Find results that contrasts with Irmen and Thisse (1998).]_

## Foresight

Prescott and Visscher (1977) criticise the Hotelling model for its assumption of costless relocation. The Hotelling model implicitly assume that firms can always relocated at a future point of time at very low cost, and therefore firms, when they choose their location, do not need to take account of future entry into the market. Instead they propose a sequential location model, where it is prohibitively expensive to relocate, and where firms therefore use foresight when choosing their location *once-and-for-all*. Firm choose the profit maximising location subject to the location of firms already in the market, and subject to the rules that future rational entrants will use. Firms use backwards inductive reasoning, ie. the last entering firm will maximise its position given the position of all other firms already located in the market. The second last firm (firm number _N-1_) uses the position of all _N-2_ firms already located and the best response of the last entering firm when choosing its location. And so on, firm number _N-2_ use the position of the first _N-3_ firms and the best response of firm number _N-1_ and _N_. This continues all the way to the first firm.

However Arthur (2014, chapter 11) is highly sceptical of this approach. Noting that there may be simple cases where every firm can figure out what to do, and where this approach produces the correct equilibrium predictions. But in more complicated scenarios or large problems with many firms the backwards inductive approach is likely to break down. The approach requires sequential location and assumes *common knowledge* and *common knowledge of rationality*. That is each firm knows the preferences of all other firms, and that each firm knows that all other firms knows the preferences of all firms, in an infinite regress. In addition each firm knows that all other firms behave rationally, and each firm knows that all other firms knows that all firms will behave rational, in an infinite regress. Further the optimal location must be unique. If any firms is uncertain about the preference or rationality of another firm, then the equilibrium solution breaks down. In essence when a firm has to choose its own location, the location of other firms is unknown. The firm can use the predicted location of the other firms. But the location outcome that each firm is trying to predict, depends on predictions that the firm and other firms form. *"Predictions are forming a world those predictions are trying to forecast"* (Arthur 2014, p.175). This self-referential loop leads to logical indeterminacy, and thus without some coordination device, the maximisation problem is ill defined and cannot be solved deductively. Nonetheless firms still make decisions even when faced with such ill defined problem. Firms possibly use heuristics or rules of thumb. Arthur (2014, chapter 11) discusses these issues in terms of a competitive location model, but does not propose a new location model that incorporates or overcomes the these limitations. Instead Arthur (2014, chapter 11) looks at a model on asset pricing, that share some of the same limitation, but is easier to solve since each investors only need to predict a single measure — the stock price. In the location model each firm need to predict _N-1_ measures -- the location of all other firms. 

In the *Santa Fe Artificial Stock Market* discussed by Arthur (2014, chapter 11, chapter 3) investors are heterogeneous both in terms of information and the expectation models they use to predict the stock price. Investors holds several hypothesis on the expected stock price[^stock-price], all of which are based on the recent history of stock prices. They act on the hypothesis that suits the current state of the market and that has given most reliable predictions in the past. They continuously discard poorly performing hypothesis and form new hypothesis. Investors use *inductive rationality* rather than deductive reasoning prescribed by the rational expectations approach. More specifically, investors hold _M_ number of hypotheses, each with a corresponding linear forecasting model. Each hypothesis is a condition/forecast rule, such that if the current state of the market matches the conditions in the hypothesis, then the hypothesis is said to be *active*. Of all the active hypotheses, the investor then uses the linear forecasting model from the hypothesis that has the best accuracy. Thus investors are able to recognise patterns in state of the market, and act using their most reliable hypothesis. The state of the market is summarised by a 12-bit array. Each bit corresponds to a scenario, such as the *“the price has risen in the last 3 periods”* or *”the current price is not larger than 16 times the dividend divided by fixed rate _r_”*. The combination of these 12-bits yield more than 4.000 different states of the market. The model uses a genetic algorithm[^GA] to create new hypotheses. These new hypotheses are created by “mutating” and “recombining” existing hypotheses. In each period when the actual stock price is reveal investors update the accuracy of their hypotheses. The Santa Fe Artificial Stock Market model is an agent-based model, where the investors are agents.

[^stock-price]: More precisely, Investors try and predict a linear combination of stock price and dividend. Dividend follows a stochastic autoregressive process, $AR(1)$, which is unknown to investors. And the stock price is given by the market clearing price after investors have chosen between the risky stock and a risk-free bond with a fixed rate _r_. Investors have a constant absolute risk averse utility function.

[^GA]: A genetic algorithm mimics an evolutionary process, ie. hypotheses are developed from earlier hypotheses with randomly occurring mutations and by crossbreeding “parent” hypotheses.

## Agent-based modelling

Laver and Sergenti (2011) also construct an agent-based model. They use this model to investigate the competitive location behaviour of political parties competing for voters on a two dimensional policy space. Political parties choose a policy and the voters vote for the party whose policy is closest to the voter’s ideal policy. They argue that the policy preferences of voters in many countries can be reduced to 2-3 fundamental dimensions. 

To study multiparty competition they assume that political parties use heuristics or rules of thumb to determine their location. They have 5 different types of political parties. Each type of party uses one of the following decision rules:

* __Sticker:__ A party that sticks to its ideological ideal policy point no matter what.
* __Aggregator:__ A party that constantly moves towards the centre of its current voter base.
* __Predator:__ A party that moves towards its most successful competitor, trying to replicate its success.
* __Hunter:__ A party that continues to move in the same direction, if the previous move proved fruitful, and otherwise heads in the opposite direction.
* __Explorer:__ A party that surveys several directions and then move along the most lucrative direction.

The last two decision rules attempts to maximise market share directly. While the other decisions rules may maximise market share, but this happens indirectly. Furthermore note that none of these decision rules considers the simultaneous move of competing parties. They implicitly assume that the other parties remain at their current location. There is no foresight and thus the decision rules are stripped of any and all strategic considerations.

The space that Laver and Sergenti (2011) considers is continuous and unbounded. They obtain this space by assuming that voters are drawn from bivariate normal distributions. They use two bivariate normal distributions which allows them to get two separate subpopulation of voters, by varying the relative size and means of the bivariate distributions. Thus their results can account for the effect of both symmetric unimodal distributions and asymmetric multimodal distributions of voters. To simplify their analysis they rotate the space such that the mean ideal points of the two subpopulations only differ along one dimension. They call this the *main axis of policy disagreement* between the two subpopulations.

There is an exogenously given number of political parties in their baseline model and all parties are of the same type. Their baseline model has many free model parameters, such as the number of firms, relative size of the subpopulation, and polarisation of the mean ideal points of the subpopulation. The parameter space is huge so using a *grid search* technique to survey each and every parameter configuration is computationally exhausting. Instead they use a *Monte Carlo parameterisation* technique, that randomly draws a sample from the parameter space. They make 1,000 repeated draws from the parameter space. Their extended model includes entry and exit of political parties.

_[Fowler and Laver (2008) use a similar model, but run a tournament in which submitted decision rules are pitted against one another ... political parties with respectively the sticker, aggregator, hunter and predator rules are reentered into the tournament ... The decision rules fall into the following categories; centre-seekers, tweaks of preentered rules, interelectoral explorers, parasites, and satisfiers/survivors ... trade-off between exploration and exploitation ... ]_


## Recap

_[**Firm behaviour:** This literature reviews has look at different firm location behaviours. The simplest being firms without foresight (zero conjectural variation). With the minimax strategy firms foresee new entry or the relocation of existing firms in a manner that will cause maximum damage to the market share of the firm, and the firm therefore locate to minimise this damage. However the minimax strategy does not consider whether the entry or relocation is a rational strategy or not for other firms, and thus it leads to an inadequate equilibrium concept. The rational expectations approach does consider this, but requires a sequential setup and very restrictive assumptions. In the field of asset pricing agents with *inductive rationality* is an alternative that has more realistic assumptions. This paper will use *inductive rationality* to analyse firm location behaviour.]_

_[aka. MAXCOV.]_
_[Different distance metrics. Manhattan, Euclidean, etc.]_