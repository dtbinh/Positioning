# WRITING JUNK

_[While writing I will consider multiple versions of the same line/paragraph/word. Rather than deleting the discarded versions I keep them, since I often return and revive these, when rewriting the text.]_

-----

## From introduction.md

*****

The assortment of products offered by manufactures is a response to the diversity of consumers preferences. 

The array of locations
The product range
The array of products offered by the firms, 
The range of available products is a response to the diversity of consumers preferences.
The array of products is a response to the diversity of consumers tastes

While consumers prefer retailers located in their vicinity to distantly located retailers.

Every consumer has a preferred variant.
The idiosyncratic preferences of consumers.

Similarly every consumer has a preferred location that would reduce the costs associated with retailer ping.

preferred location that reduce the consumers costs

Consumers have distinctive preferences
Consumers have idiosyncratic 
 — whether it be product or location.
 
 Consumers have idiosyncratic tastes about their most preferred variants.
 
 The product range is a response to the diversity of consumer preferences.
 
 , and is the source of the market power of firms. 
the source of market power
The premiums give rise to the market power of firms.

The market power of firms arise from these types of premiums.
The source 
The firm gains market power of firms 
These types of premiums is the sources of the market power of firms.
The market power of firms 
 and diffusion of retailer location.
The intraindividual heterogeneity

This intra- and inter individual heterogeneity generates a demand for product diversity in the aggregate.
It follows that consumers pay more for variants that are better suited to their own tastes. These premiums are the source of market power of firms.

and so it is unlikely that each individual can sustain producing his or her preferred product.

Although the market exhibits a wide diversity in consumer preferences, the market is

Inspire of the wide diversity in consumer preferences, the market  is unlikely to support a large number of firms, because of increasing returns to scale in production, distribution, R&D etc.

Despite wide diversity in tastes, the market is unlikely to support a large number of products because of increasing returns to scale in R&D, productions, marketing, and distribution. Otherwise each individual would produce his or her own preferred product. Each firm must capture a sufficiently large fraction of demand to cover its fixed costs. Competition takes place among the few remaining firms.
When competition is among few firms, the assumption of competitive price-taking firms becomes untenable. The interaction among firms is strategic.

When a profit maximising firm evaluates different locations or product characteristics, it should take account of the potential demand associated with . 

Profit maximising firms should take into account the potential demand of different

Profit maximisation dictates the firm should account for the potential demand of providing different packages of characteristics. The firm with foresight should also consider the implications of introducing a particular product on (possible) product repositioning of other firms.

 once we analyse the model.
 
In sum, when discussing

 the long-term profitability is contingent on the firm's ability appropriately incorporate the action of competing firms.  
Since firms compete for the same consumers,
Several firms compete for the same segments, and so 

The firms compete for the same segments of the market
The Tactical
Navigating in a market with competing firms ... 
Capture a sufficiently large share of the market.
The strategic non-cooperative behaviour of firms, imply that several firms are likely to compete for the same segments of the market. And so it is not enough that the choice of the firm is profitable given the current state, its actions should be profitable in   
The choice of the firm should not only be profitable given the current state, but  _[FORESIGHT. Why? Why interesting?]_

Not only profitable given the current state, but continue to be profitable ... 
Niche ... 

less well understood. M

 .appearance dimension.

that specify the clean differentiate their product along several product -- such as a two dimensional geographical space, or when products differentiation takes places along multiple dimensions
 a product space with multiple  product differentiation  how firms locate in a two dimensional space or which product characteristics firms cho   along multidimensional product characteristic. 
 
   With little knowledge of how these decisions are made, or how they affect the overall market. Without a solid theoretical understanding

 _[In a market with fixed prices, consumers view variants that better mirror their preferences as less costly, allowing firms to maintain an excess demand, which also give rise to market power.]_
 
  and the analysis framed in terms of geographical location or product differentiation. 
This paper
Out-compete
The aim of this paper is not to aid or guide firms in their decision process, but rather to develop a theoretical fundament that can be used to understand the decision process of firms. The theoretical foundation is of little practical use in itself. 

Moreover consumer preferences are not necessarily distributed uniformly or symmetrically, and might no be single peaked. ... Convenient 

 Making it imperative to also consider distributions that are not necessarily symmetric or unimodal.  
When analysing this s also consider distributions which are not necessarily symmetric nor unimodal. 
 the distribution of consumer preferences might be asymmetric and multi-modal.  
market not necessarily restricted to a single dimension and where

the market power   
A theoretical model opens the field to more practical applications and.  
A thorough theoretical   

However developing a theoretical understanding allows us to answer more practical useful questions, such as ... 

... try to mitigate the inefficient locations or product range by adjusting incentives accordingly. 
  
- When firms compete via the product they choose to produce, an additional possible source of market failure can arise in the product selection process. I.e having too many, too few, or the wrong products. ... endogenous product selection. Whether firms choose the right products from the spectrum of possible variants.

- Market power --> relevant for competition laws/anti-trust laws

This type of reasoning  

In this paper we extend the agent-based model of Laver and Sergeant (2011) to include a decision rule
 
 *Santa Fe Artificial Stock Market* discussed by Arthur (2014, chapter 11, chapter 3) 
 
This paper uses a modified version of the forecast method advanced by the
 Forecasts are
The way this paper models incorporates forecasts is a modified version of
The method used *Santa Fe Artificial Stock Market* discussed by Arthur (2014, chapter 11, chapter 3)
 
However the lack of foresight prohibits any type of strategic considerations. That is, each agent is oblivious to the future behaviour of the other agents and does not take their behaviour into account when deciding its own location. Strategic considerations are fundamental to the equilibrium concept of the earlier competitive location models.

Price may also have been fixed earlier in the distribution channel, if firms
Prices may also have been fixed earlier in the distribution channel, e.g. by manufactures or wholesalers, if firms enter a *retail price maintenance* agreement.  

Price competition greatly increases the complexity of the model. 
, and is therefore beyond the scope of this paper.
   In the models we assume that all firms charge the same price, and thus we disregard price competition altogether. Price competition greatly increases the complexity of the model, and is therefore beyond the scope of this paper.

The term firm, retailer, manufacturer and political party 

While the models in this paper are
We reformulate the model in terms of firms competing for customers, when they choose their geographic location. It is simply shorter to write ‘firms’ and ‘relocate’ rather than ‘political parties’ and ‘shift policy position’ and it reads more naturally. The results of the model are still valid in a political context, as well as in the context where manufacturers competing for customers through product differentiation when choosing product characteristic along two dimensions.

Instead of jumping right in, the paper gradually introduces decision rules and extensions, starting from the most simple and adding extra layers. Decision rules are gradually introduced, starting with the most simple 

section The decision rules are gradually introduced starting with the simplest decision rules and distribution of consumers, advancing into asymmetric distributions, and finally covering the decision rules with foresight.

## From Literature review.md

in the Hotelling model

Similarly the research in the last 85 years, since Hotelling published his paper, show that

 such a linear quadratic transport functions or three firms (Eiselt 2011, Eaton and Lipsey 1975).

that the model is not robust when the various 

In the 85 years of research since Hotelling published his paper has shown that

 The general result from the literature on spacial competition in the 85 years of research has shown that that the Hote

This is just one example of how the results in the Hotelling location model fundamentally change when assumptions are modified. not robust to
Although the H

An error lead Hotelling to the wrong conclusion in the model with price competition.

the closer the firm locates, the more price competition intensifies. 

and the the more 

For each firm there is a trade off between two opposing forces; 
by locating closer to the competing firm
by differentiating location 
For each firm there is a trade-off between; differentiating to relax price competition and closer to rival attracts more consumers

there is a unique pure strategy equilibrium where

 This equilibrium is not
ex  firms charge the same price 

* is typically measured. is the cost endured by customers 

It is socially suboptimal. If the market was split in two halves and  , whereas in the social optimum firms locate at the centre of each half of the market, the average distance is one-eighth. 

 firms spilt the market in half, but locate at the centre of their respective market area. Here


The closer the firm locates to its competitor, the more consumers it attracts. But the closer the firm locates, the more 

Researchers find that conclusions are non-robust across alternative model specifications

In the last 85 years since Hotelling published his paper, researchers have generalise the model, but found that conclusions are non-robust across alternative model specifications. Most results are falsified when assumptions are modified. And even minor modification may remove any equilibrium constellations.

 The reader will see how results change when assumptions are relaxed, 
Below I will go through some of the 

For exhaustive review Several papers pr reader to some of the previously published reviews on the topic. 

change assumptions regarding firm behaviour from what they call *zero conjectural variance*, ie. firms with no foresight.

,  each measure results in a different Voronoi diagram]_  can be constructed with different measures of proximity.

  Each firms market area therefore consists of all the consumers that are located closer to the firm,  the  the objective of firms corresponds to maximising its market share.

the objective of firms is to minimise the su
A Voronoi diagram is a geometrical construction related to the allocation problem. The Voronoi diagram consists of several Voronoi set. Each Voronoi set contains all the points that are closer to each firm or *seed*.
Allocation problem

A Voronoi diagram is not unique in the sense that several different locations of firms or *seeds* may lead to the same Voronoi sets and tessellation. The unique Voronoi diagram where firms or *seeds* are located at the centroid of the Voronoi set is a special case called the *centroidal Voronoi tessellation* (Laver and Sergeant, 2011). Here each firm is located at the mean or centre of mass of its Voronoi set. Thus the
—> Representativeness 

![Voronoi diagrams are not unique. Several firm or seed locations can lead to the same tessellation. In the centrical Voronoi tessellation firms or seeds are located at the sets centre of mass.](Graphics/Nonunique_CVT.png)

The Minkowski distance measure statistic
If the Minkowski distance meassue is used with the usual parameters  Polygon


That is Minkowski distances with the usual parameters p = 1, 2, ∞ 

Perimeter

Teramoto, Domaine and Uehara (2006) consider the discrete Voronoi game where firms locate facilities on a network. 

take turns and

 place or relocate

In the Voronoi game is sequentially two firms in turns choose the location of _p_ facilities.

consumers are distributed on a continuous two-dimensional area

 The two firms take turns and place or relocate

(Easel and Marianov, 2011, chapter 9)

_Spatial-temporal process_
What happens to shape when change? vs. shape stable

In the model products  however are where each product

An other approach altogether 
Besides competitive location models where firms locate in real space, the 
The literature on competitive location parts with 

also makes an abstraction away from continuos real space and the linear ordering.

also left the real space
Competitive location models have also been studied
Non-euclidean space-.

, that is if the current market state corresponds the the investors predictions, then these predictors are *active* and the most reliable of these is then

 descriptors  

 using a generic algorithm

 behave like staticians, and that the try to predict the stock price in the next period using a

Their baseline model has an exogeounsly given number of political parties and all parties are of the same type. They find that more parties will result in 

o analyse the model across the entire parameter space they use 

contains many free 

However no firm will have a total market area that is less than one of the market areas on either sides of any firm (also referred to as the two *half-markets*).

There are also problems where firms have multiAnd the problems that look for the locations of multiple firms or facilities that minimise the sum of each firm distance to its consumers in a plane is known as .

   The market area of each firm contains all consumers that are located closer to the firm than any of the other firms. Combining the market area of all firms result in a *Voronoi tessellation* or *Voronoi diagram*. 
 The market areas of firms can

The algorithm prescribes that at every iteration the firms or *seeds* should move to the current centroid of its Voronoi set. By iterating this process a Voronoi diagram will converge to the *centroidal Voronoi tessellation*.

_[In the one-dimensional line market the market areas created by two firms locating at respectively one-fourth and three-fourth the length of the line constitutes a *centroidal Voronoi tessellation*.]_

or firms are 
 is where firms are located such that all the market areas create a *centroidal Voronoi tessellation*

 Depending on the shape and boundaries of the space there may exist 

The models discussed so fare can be formulated in terms of product differentiation rather than of geographical location. 

 The ideal point of the consumer is his or her location. , and the ideal point of all consumers are distributed over the entire space.

The models discussed so fare strictly consider *horizontal product differentiation*. Consumers have heterogeneous preferences regarding products or firms. The ideal point of the consumer is his or her location, and the ideal point of all consumers are distributed over the entire space. 

Runic (2012) considers vertical product differentiation. Runic (2012) does not model products on a scale, but instead defines products as a bundle of characteristics. The two firms choose which of the _Q_ characteristics to include in their product. The preferences of consumers is given by a joint density function. They find that in equilibrium the product of one firm includes all _Q_ characteristics, and that the degree of product differentiation between the firms depend on the correlation between the characteristics. Núñez and Scarsini (2014) considers competition over a finite number of discrete locations. They find that an equilibrium exists when there is sufficiently many firms in the market. Additionally they find that as the number of firms increase, the distribution of their locations converges towards the distribution of consumers.

_[Competitive location on networks:]_

- Transportation_Science_Volume27_Issue1_1993 (25768565, 25768566)
- Fournier_Scarsini_2015
- Heijnen_Soetevent_2014
- Bauer_Domschke_1993
- Hansen_Labbé_1988
- Hansen_Thisse_Wendell_1986
- Serra_ReVelle_1998
- ReVelle_1986
- Bodson_Karmarkar_1987
- Drezner_2011 (16 Competitive Location in Discrete Space)

##Political Science and Political Economics 

_[Denzau, Kats and Slutsky (1985) : Firms that also have a rank objective.]_

s difference between the two subpopulations take place along one of their dimensions.

##Predictive analysis
GACH, Multinomial distribution with Dirichlet prior distribution.

_[Voronoi diagrams and Delaunay Triangulation.]_

  depends on the distance metric used. can be constructed with different distance metrics, each resulting in a different Voronoi diagram.]_

 note that equilibrium “sometimes exists on multidimensional policy space but existence is undependable”.

_[Quote from book/paper with author that propose two alternative models (one which he developed himself which is sequential rather than simulanoues)]_

_[One might then ask, why the model appeals to researchers and why the continued interest in the Hotelling model?]_

In relation to the models with multidimensional space, Roemer (2006, p. 1018) note that equilibrium sometimes exists, but *“existence is undependable”*. And goes on to write that many researchers *“took the non-existence of multidimensional equilibrium in the known models to mean that in reality there was no equilibrium … and hence one should observe cycling”* (like the *dancing equilibria* mentioned above). Roemer is highly critical of this line of reasoning, writing that an equilibrium theorist *“does not conclude that if her model fails to produce equilibrium, there is no equilibrium in the real world; this would be a last resort. Instead, she looks for another model”*[^othermodel]. 

_[Agent-based model might be this other model. … We reject cycling as an equilibrium, since it violates our assumption that of anticipation. Something I try to correct for by assuming that agents use inductive reasoning.]_
_[(Paradigm shift? Lack of alternative model/explanation?)]_

[^othermodel]: Roemer (2006) himself points to two alternative models in the literature on political science — the *party-faction model* and the *citizen-candidate model*. Neither of which are particularly suitable to settings outside of political science.

This further implies
This further implies that the methods used to construct Voronoi diagrams do not easily generalise to other 
The methods used to construct Voronoi diagrams are often exclusive to one distance metric. 
Unfortunately the methods that use one distance metric to construct Voronoi diagram, do not easily generalise to other
Unfortunately the methods for constructing Voronoi diagrams that rely on one distance metric, do not easily generalise to other distance metrics.

Methods that construct Voronoi diagrams for one type of distance metric do not easily generalise to other distance metrics

used choice of distance metric

In the line market with three firms, the Delaunay tessellation will not link the two firms on the perimeters together, since they do not share a market boundary, however both these firms are linked to the firm in the middle.

In a bounded two-dimensional space, each Voronoi set creates a polygon[^poly]. The number of sides, the area and the perimeter of the polygon are measures that can be used to characterise the Voronoi set (Okabe, et. al. 2009). In terms of firm location these three measures would be the number of direct competitors, the market size, and length of the market boundaries. _[The latter is a proxy for the surface tension/energy of the market. The points on the market boundary exhibits higher energy than interior points.]_ The properties of the polygon provide descriptive statistics on each firm. However they contain less information on the intrinsic interaction between firms that is an integral part of competition. The network formed by *Delaunay tessellation* provides insights on interaction. The number of direct competitors can also be obtained from the network by counting the number of links emanating from a firm. But more importantly the links tell which specific firms are in direct competition with one-another, and in a dynamic setting they tell how the competitive setting changes over time. As earlier noted, Eaton and Lipsey (1975) find that the hexagonal, square and rectangular pattern break up because firms on the perimeter will pair up with neighbours. The *Delaunay tessellation* provides an easy method to analyse such behaviour and a method to generalise the findings. _[The *Delaunay tessellation* seem to be under-explored in the contemporary literature on competitive location of firms.]_

[^poly]: Strictly speaking, the Voronoi set is only a polygon for certain distance metrics. Only distance metrics where the boundaries of Voronoi sets are line segments will lead to polygons. Commonly used distance metrics -- such as *Manhattan*, *Euclidean* and *Chebyshev* -- all fulfil this requirement (Eiselt and Marianov, 2011, chapter 19).

##Price competition

_[Although this paper does not consider price competition I would no the less like to highlight a couple of papers that may indicate how the results in this paper might change if price competition was included ...]_
_[Irmen and Thisse (1998) : multiple dimensions. Equilibrium with maximum differentiation along one dimension (the dominant), and minimum differentiation along all others.]_
_[Liu and Shuai (2012) : Find results that contrasts with Irmen and Thisse (1998).]_

Another string of papers part with Euclidean space altogether, and considers firm location or product differentiation in discrete space, such as on networks. Gaskin (2008) provides a review of discrete spatial competition models.

 is  
Arthur (2014) describe *inductive rationality* as the process of acting upon the most suitable hypotheses and update hypothesis in response to new information that falsifies currently held hypothesis. Investors use *inductive rationality*, as opposed to deductive reasoning which a rational expectations approach would prescribe. 

. dictates that firms deduce firms are said to use  in their decision process to derive the optimal location. 

Firms 
The location model in this paper is ext will incorporate inductive 
A modified version of this model is incorporate into the location model This paper will incorporate The location model in this paper incorporates the 

They argue that the policy preferences of voters in many countries can be reduced to 2-3 fundamental dimensions. 

 distributed  This allows them to get two separate subpopulation of voters, by varying the relative size and means of the bivariate distributions.

number of political parties in their baseline model 

Their baseline models has many free model parameters, such as the number of firms, relative size of the subpopulation, and polarisation of the mean ideal points of the subpopulation. 
The parameter space is huge and they use a *Monte Carlo parameterisation* technique to set, that randomly draws a sample from the parameter space. They make 1,000 repeated draws from the parameter space.
so using a *grid search* technique to survey each and every parameter configuration is computationally exhausting. Instead

 Political parties exit the   The decision rule of firms is randomly selected in these model. By analysing these  models they see how decision

 ... trade-off between exploration and exploitation ... ]_

political parties with respectively the 
 are pre-entered into the tournament ... The decision rules fall into the following categories;
count towards and are only evaluated based on their votes elections periods are   

The only decision rule that approaches  
 
It is worth noting that none of the submitted decision rules use foresight. 

The genetic algorithm used Arthur (2014) by 

The model uses a genetic algorithm[^GA] to create new hypothesis. The new hypothesis are created by “mutating” and “recombining” existing hypothesis. 

[^GA]: A genetic algorithm mimics an evolutionary process, ie. hypothesis are developed from earlier hypothesis with randomly occurring mutations and by crossbreeding “parent” hypothesis.

conditional probability of  then the probability of that event occurring in the future increases.
_[Learning]_

way of overcoming
 numerical sim   The macro-behaviour of the system is often I’m emerges from   not the same as solve numerically … agent-based model or out-of-equlibrimm economics is generalisation of equilibrium economics. As seen in the Santa Fe Artificial Stock Market model where standard equilibrium behaviour is a special case of the model.]_
pursuing these by using decision rule,
often simple

_[Definition of agent based model]_


using conventional analytical techniques the problem is very complex, perhaps intractable

solve the model analytical is intractable.
While there are settings in which trade agent-based models provide results in settings

_[Different distance metrics. Manhattan, Euclidean, etc.]_

or relocation

In the field of asset pricing agents with *inductive rationality* is an alternative that has more realistic assumptions.
In addition the agent-based model from the literature on political science allow researchers to analyse the two-dimensional multi-age
In the field of asset pricing agents with *inductive rationality* is an alternative that has more realistic assumptions. This paper will use *inductive rationality* to analyse firm location behaviour.

_[**Firm behaviour:** ]_

This literature review has gone through the different behaviours which might choose when choosing their location in a competitive  location behaviour

This literature review looked at different firm location behaviours. The simplest being firms without foresight (zero conjectural variation). 

_[aka. MAXCOV.]_


## From Draft.md

Therefore the other side of the market -- consumers and their purchasing behaviour -- has been greatly simplified.
It therefore uses simplifying assumptions for consumers and their purchasing behaviour.

 

 and the further way points further away are less
This is the point at which the consumer would prefer the firm locates at. All other points are second to the ideal point, and 
Every consumer is merely her ideal point in the market. The ideal point 
This is the preferred position or location of the consumer.
Every consumer has an ideal point in the market. 

 
The above described consumer behaviour with no interaction among consumers simplifies our model and

This this method of two soft probably from sup populations allows us to capture their sleep different distributions
of asymmetric and multi-modal distributions


Instead of having a finite number of consumers dispersed across the market given some distribution.



 constituting two separate markets.

to the point where   and it might be more precise to describe the.   

With no overlap it might more appropriate be described as two separate markets, rather than one market.
it might be more appropriate to de of two separate markets rather than .


Taking the mean over all firms gives us the mean eccentricity.
We would like to describe the position of the firms. In 2D space each position is a 2D vector. Would like a single measure of the position. The measure should be relative making it inturpretable. And the measure should be comparable across different parameter settings. We use eccentricity. This is the distance from the firm to the mean ideal point of all customer. Taking the mean over all firms gives us the mean eccentricity.


The relative market shares of the firms
To summarise the relative size of firms I use the measure
I use the *effective number of parties* (ENP) which   

Laakso and Taagepera (1979)
Effective num

Eiselt and Marianov (2011)

Competition

and not a single firms that manages to capture one-half of the market 
it is not a single firm that manages to capture one-half of the market, but always a small group of firms.


The firm can instead use the predicted location of the other firms. But the location outcome that each firm is trying to predict, depends on predictions that the firm and other firms form. *"Predictions are forming a world those predictions are trying to forecast"* (Arthur 2014, p.175). This self-referential loop leads to logical indeterminacy, and thus the maximisation problem is ill defined and cannot be solved deductively.


Instead of the directly aiming firms may use heuristics or rules of thumb.

Nonetheless firms still make decisions even when faced with an ill defined problem. Firms possibly use heuristics or rules of thumb. A firm could choose:

This centre is known as the *centroid*
The weight is the density of customer.

weighted

 within it's the market area.
 mean ideal point of it.
The firm locates at the mean ideal point of its current market area.
or centre of its current market area. 

[If all competing firms maintain their current position, then relocating to the centroid will leave the market share of the firm unchanged.
The firm will retain their current market area if 
Assumption on other firms: the firm will reach the current centre if all other firms main their current position.]

in
 resulting firm location will be
inertia  in all-hunter model leads to CVT. Since it is equivalent to Lloyd’s algorithm 


The assumption that is has perfect knowledge of its current customer base. Knows the span of its market area and the distribution of customers within the area such that it can perfectly determine the mean ideal point of the market area.

* to move towards the center of its current market area. 
* to move towards its most profitable competitor.
* 
* to survey several directions and move along the most profitable.

knowledge of competing firms or

What matters in 
Short/gold fish memory, only knowledge from the last periods is used in the firms decision process. Which is more suited in a fast evolving market, where exploration of new opportunities fruitfull .

be able to account for some of the ... that undoubtedly is present in the real world

it predicts the location of competitors. location predictions and .

of how a firm chooses to locate when the direct objective is to

choose location that formed our basis.

Bridge / Motivations for maxcov.

The latter two decision rules attempts to maximise market share directly, while in the former two the market share may be maximised, but only indirectly. Laver and Sergenti (2011) use decision rules similar to these. Further note that none of these decision rules considers the simultaneous move of competing firms. They implicitly assume that other firms stay at their current location. And thus the decision rules are stripped of any and all strategic considerations.

indirectly try to maximise shares.



to choosing the location that maximises the share of the firm when entering a market with existing firms which the firm itself is not part of.
two effects when a firm relocates

inherent
 measure increase
 but may be impossible to find exact solutions when work with the *Euclidian* distances since the 

in such a way that structure of the Voronoi diagram is unaffected by any 
The 
These regions preserve the structure of the Voronoi diagram


so its unclear how this approximation would work with a non-uniform distribution. The largest empty 

To allow location through the entire market space the Delaunay Triangulation is constructed using the location of all competing firms and the boundary points 
The boundaries are included such 


There is no limit as to how far an *aggregator* firm can move at each iteration, although the firm never relocates outside its current market area. And the firm tends to move in relatively small steps.  
and given that the market is not too unstable,
_[speed. will never relocate outside its current market area]_


In could be interesting to consider the effects from changing this *speed* parameter, however this is beyond the scope of this paper. 


_each consumer has ... _ 
_all firms are identical in the eyes of the consumer / **no loyalty** or brand_
_no interaction between consumers _

Additional firms do not push others further out, instead the *maxcov* firms locate within a rhombus shaped area that is centered on the population mean. 

Mean eccentricity only increases slightly as the number of firms are increased in the all-maxcov model. 

Two *maxcov* firms locate in the same fashion as firms using the aggregator rule.

_All-Maxcov mean eccentricity:_ For N=2 the firms using the hunter rule tend to locate fairly close to the population centre. While the firms using the maxcov decision rule locate farther away, and locate in the same fashion as firms using the aggregator rule. For N=2 this is the CVT. 
In the all-maxcov model there is only a slight increase in the mean eccentricity 

--less than 7-- 

In the all-aggregator model the market is split evenly for the two and three firms. 
The all-aggregator model maintain a even split of the market for two and three firms. the all-aggregator model effe

The concentration of customers amoung firms is highly uneven in the all-sticker model. 
The most uneven concentration of customers is in the all-sticker model.

_All-Maxcov ENP:_ In a market with firms all using the maxcov decision rule, the firms tend to split the market share more evenly than with any of the other decision rules. Although the mean estimate is less than N for N>4. The standard deviation (confidence band) show that there are several runs where the market is evenly split among firms.

The results from this model therefore reflect how we choo ... As expected the mean eccentricity is 1.5 in the all-sticker model. This follows directly from the initial position of firms, which is drawn uniformly form a circle with center at (0,0) and with a radius of 3 standard deviations. The sticker firms do not move a thus the average distance to the population center is 1.5. 

The three other models show signficanly lower mean eccentricity. *Aggregator*, *hunter* and *maxcov* firms have the same initial posision as *sticker* firms, but they all move towards the population center. With the *hunter* firms locating closer to population center compared to *aggregator* firms. Firms that constantly search higher market shares locate closer to the center than firms that try and satisfy their current customer base. The distance to the center increases with the number of firms in both the all-aggregator and all-hunter model.

In the all-hunter model the firms agglomerate at the center. However not perfectly since the *hunter* firm never settles down, but constantly explores, which also shows in the confidence bands of the all-hunter. This creates the small perturbations away from the center. This perturbation is smallest when there is only two firms. _[As the number of firms increases, so does the total disturbances.]_ _[Additionally increaseing the number of firms crowds the center pushing other firms further out.]_

 and leads to a low effective number of firms.

The model show that when 

The models show that when firms compete againts other firms that 

These models show that when homogenous agents or firms compete over location, the

of the market becomes more differcult and the ENP   
As the number of firms increase

the the even split cannot be maintained.
As the number of firms in the market increase it more to maintain the symmetic 

The board conclusions on the effective number of firms is the same for the all-aggregator, all-hunter and all-maxcov models. _[But there are small difference highlighting distinct aspects of each decision rule.]_ In all three models the market is evenly split when there are two firms present in the market. As the number of firms increase the the even split cannot be maintained. The effective number of firms increase slower than the actual number of firms.

With few firms the all-aggregator model results in a market that is more evenly split, compared to the all-hunter model. While the oppersite is true when there is more than 7-8 firms.

The all-maxcov model splits the market more evenly than any of the other models. And all though the estimated effective number of firms falls short of the actual number of firms already after 4 firms, the standard deviation (confidence band) show that there are always cases where the market is evenly split among all firms. This is not the case for the other decision rules.

We know that our all-aggregator model will maximise our mean representation measure, since the model results in the CVT. 

_[Partial conclusion: the social optimal location requires location further away from the population center. And in a market with many firms it will also require a more uneven split of the market.]_

Similarly in the models with high polarisation the firms tend to locate around  
to a seperation among the firms when there are four or more firms in the market.
a crowd of firms engaging in fierce competition over a subpopulation.
into two groups, with each group in
The reason for this is that with four or more firms in the market
With four or more firms in the market we typically see that a group of firms -- consisting of two or more firms -- compete over one of the subpopulations. The dynamic of the competing group is such that they keep each other at bay. Although competition is feices close to the center of the subpopulation, divereging is associate with a loss for the particular firm.
The firms competeting will 
two or more firms compete around one of the subpopulations. Moving away from the subpopulation 
Further increasing the number of firms in the market does not 
We see that there is a a 
Comparing the *aggregator* and *hunter* firms show that 

In the highly polarised *hunter* model there are two modes in the consumer distribution. 

With a one-dimensional line market there is only two option and that is to approach the optimal point from the left or from the right.
locate on either side of the optimal point.
The pairing of firms in two and the $2M$ limit follows from the one dimension they consider. That is on a one dimensional line market the firms only option is to locate on either side of the optimal point.
--at least for some distributions of consumers-- 
*”there is some indeterminancy in the location of the firms (at least for some density functions)”*  (Eaton and Lipsey 1975, p. 36).
 Eaton and Lipsey (1975, p. 36) furthermore note that
*”When the number of firms is 2M, conditions ... require that the firms all be paired … When n < 2M, there is some indeterminancy in the location of the firms (at least for some density functions)...”*
The paring in the right panel of Figure 5.8 seems to support the first part of this statement.

_[Relate to Eaton and Lipsey (1975)]_
The change when going from 2-3 firms and into the realm of four or more firms seems related to an observation that Eaton and Lipsey (1975) made when considering asymmetric distributions. Although Eaton and Lipsey (1975) considered a vastly different setting, namely the bounded one-dimensional space (line market).

A high degree of polarisation amoung the subpopulation

With asymmetric distributions you have created 2 modes in the density of voters along the x-axis.

Eaton and Lipsey (1975) also considers asymmetric distributions in the bounded 1D space (line market). 
Might this be what gives a sudden change when going from 2-3 firms to 4 or more firms in the all-Hunter model?

You write that you experimented with more than two subpopulations. I am guessing this would give 3 modes in the density along the x-axis. With three subpopulations do you then observer a change going from 2-5 firms to 6 or more firms? Or does the big change still take place when going from 2-3 to 4 or more firms?

and as the 
symmetric distribution show

any degree of polarisation among the subpopulations make the *maxcov* firms seperate. In contrast, at a low or medium degree of polarisation ($0.5 < \mu < 1$) the two *hunter* firms agglomerate relatively close to the population center.

The subpopulations need not  
 
Furthermore even a low degree of polarisation among the subpopulations 

will lead to *maxcov* firms seperating

into each subpopulation even when

Even and degree of polarisation make the *maxcov* firms always seperate, a

into crowds that compete for
locate 

, here the maxcov firms located at the same distance as *aggregator* firms.

The average distance in the maxcov is 

widens the populated area and thus 
 
to locate in circle 

The slightly lower ENP in the *aggregator* model compared to the *hunter* model when there are many firms completely disappear when the subpopulations are polarised. 

A single firm or even two firms occupying one half of the market are likely to be attack by other firms.
However the in-fight competition in each subpopulation allows a small majority of firms to capture a disproportional amount of the market.
_[Image of all-maxcov uneven split, N=12 mu=1.5 n_r/n_r=1.]_

the two crowds are not necessarily the same size.

Looking at the ENP in the *maxcov* model the 
_All-Maxcov ENP:_ The more polarised the subpopulation is the more inequality among the market share of firms. What happens when $\mu$ is large, is that the subpopulations is split, and a minority of the firms often manage to capture one-half of the market. This pulls down the ENP. 

_All-Maxcov:_ What happens around N=6 and N=7 ??

We know which competitive enviroment results 
We know how the location behaviour translates into 
We know which type of competitive enviorment and   the location behaviour of the firms translate into 
 
 how firms locate using these decision rules. 
 The three heuristic decision rule; *sticker*, *aggregator* and *hunter* -- and the the *maxcov* decision rule, which deliberately and directly aims at maximising the market share. 
 
 The hypotheses come in the two-part form of *condition/forcast* rules. The condition part is

The condition part specifies what states the hypothesis covers.

The descriptor $J_j$ consists of 13 bits and each bit can take the value 1 or 0. 

, eg. `1110010011010`.

relates to a particular state and

The firm holds several hypothesis that fit a wide range of different situations. And at each iteration the firm will select the hypothesis that fit the current situation.

And when predicting the future locate of competing firms the firm acts on the hypothesis that previously proved most accurate. 
 
A 13-bit descriptor of the state of each firm's location.

The location behaviour of each firm is summerised by the state variable $J_i$. The state variable $J_i$ is a 13-bit discriptor.

Out of these hypothesis often only a handfull will fit the current situation.

These hypothesis need not fit any situation, some hypothesis might be specific and the firm will only use the hypothesis if

The firms uses the predicted location of all competing firms to decide where it itself should locate.

to make predictions on the future location of all competing firms. The firm these predictions when deciding where to locate.

Eg. which states 
part specify h

A firm with the _[maxcov-inductor]_ decision rule make predictions on the future location of all competing firms and uses these predictions when deciding where to locate. The firm maintains several hypothesise at any point in time. When predicting the future location of a competing firm the firms uses the hypothesis that fits the current state and that previously proved most accurate.

Such that at each iteration only

* current state
* hypothesis that fit many different situations

Eg. the hypotheses are specific to the current state, and forecast  hypothesis

The firm retains an array of hypotheses covering a wide range of different situations, but at every iteration the firm only considers the hypotheses that the fit the current state.

and at every iteration only considers the hypotheses that fit the current state. 
and at every iteration only  
The firm has 

The firm holds many hypotheses that together fit a wide range of different situations, but at every iteration it only considers the hypotheses that fit the current state. 

the hypothesis and thus which.

The firm is endowed with $M$ number of hypotheses _[that together cover a wide range of different situations]_. Each hypothesis consists of two parts that jointly form a *condition/forcast* rule. The condition part specifies which situations trigger the forecast. _[Thus at every iteration the firm considers the hypotheses specific to the current state and ignores the remaining hypotheses.]_ To describe the current state of each firm we use a 13-bit descriptor. The descriptor $J_j$ summarises the location behaviour of firm $j$.

Each bit takes the value 1 or 0 -- the value 1 if the state occured and takes the value 0 if the state is absent. _[Eg. the 13-bit descriptor may look like `1110010011010`.]_

The descriptor is used in conjunction 
A condition then specifics which bits most be satisfied and which  
The condition `###1#####0###` will match any state where the firm is more than 0.6 standard deviations away from the population center and it position along the y-axis is not above the average of the last 16 periods. 
The value 1 require that the state described by the corresponding bit is true. The value 0 require that the state is false. And the value # matches either case.
The # is a wildcard that matches either case. 
Three selectors are used in the conditions; 1, 0 or #. A 1 will match 
A condition consists of 13 position where each position can take the value 1, 0 or #. The value 1 in
Th fourth position in the condition is 1, then it 
There are 13 corresponding positions in a condition, each taking the value 1, 0, or #. A 1 in the condition says that
A condition has 13 positions corresponding to the bits in descriptor, 
There is 13 corresponding positions in a condition that take the values 1, 0, or #. The condition matches the current state
A condition has 13 positions corresponding to the bits in descriptor. 
Each position can take the value 1, 0, or #. 
Correspondingly the condition has 13 positions and each position can take the value 1, 0, or #. 
A 1 corresponds to the condition being fulfilled, a 0 is not fulfilled, and # match either case. 
A value of 1 matches
The condition have 13 corresponding positions where each position take the value 1, 0 or #

Correspondently the condition that match the current state consists of 13 positions and each position take the value 1, 0 or #. 
The *condition/forcast* rule can recognise states
Each of the 13 positions in the descriptor $J_j$ take the value 1 or 0 depending on the current location of the firm. E.g. the fourth position in $J_j$ takes the value 1 when firm $j$ is more than 0.6 standard deviations away from the population center. The tenth position in $J_j$ takes the value 1 when firm $j$ position along the y-axis is above the average of the last 16 periods. _[(along the dimension where the consumer subpopulations are in agreement).]_ Etc. Our 13-bit descripter is able to describe $2^13 = 8.192$ distinct states.

this paper will use standard deviations when reporting on the distance between two firms.

, or when reporting on the average distance of all firms to the mean ideal point of all consumers, etc. 

The standard deviation measurement used in the bivariate normal distributions will be the default unit of measure throughout this paper. 

A *bivariate normal distribution* with mean (0,0) and with standard deviation (1, 1).
the *bivariate normal distribution* with mean (0,0) and 
Throughout this paper many of the measure

$\left( \begin{array}{c} C_1 & C_2 & A_1 & B_1 & A_2 & B_2 \end{array} \right)$

_[This implies that a *condition/forcast* rule might be updated multiple times in one iteration, if the firm uses that same rule to forecast the location of multiple competing firms. The probability of this happing increases with the number of firms in the market. The updating frequency of the *condition/forcast* rules is disproportionate to the number of iterations. And the updating frequency may get skewed as the number of firms in the market increase.]_

_[The 13-bit descriptor can describe 8.192 distinct states.]_ _[??? However the bits are not undefended so less that 8.192 states ???.]_ 

The following section looks at how firms choose to locate when they also consider the predicted future location of competing firms.

The following section looks at how firms choose to locate taking into consideration the predicted future location of competing firms.

will investigate the competitive location behaviour of firms that make predictions 

_[The following section will investigate the competitive location behaviour of heterogeneous firms. These firms will attempt to predict the future location of competing firms. In addition learning will be part of the behaviour of firms.]_

Learning takes place through the continuous updating of the accuracy of the *condition/forcast* rules. 

The _[maxcov-inductor]_ firm learns  

therefore reasonable to use 

are reliable and can be work well

And so the firms tests the prediction of the hypotheses against the observed location of the other firms.

By testing the prediction of the hypotheses against the observed location of

This process channels the accumulated knowledge from testing predictions into the new hypotheses. New hypotheses

Something that 
We would like new hypotheses to perform better or at pair with existing 
This process channels the knowledge accumulated by testing predictions into the new hypotheses.

These new hypotheses are adaptions and revisions of the currently best preforming hypotheses, thus implicitly passing on the knowledge accumulated by testing of predictions.

Because the hypotheses are adaptions and revisions of the currently best preforming hypotheses they implicitly passing on the knowledge accumulated by testing of predictions.

New hypotheses are adaptions and revisions of the currently best preforming hypotheses, rather than independently created hypotheses

Besides being endogenous, 
The hypotheses are adaptions and revisions of pre 
The hypotheses are not only endogenous, but they are 
This means that the endogenously created hypotheses are adaptions and revisions of pre 

the hypotheses are exogenously given to the firm.

In the first decision rule considered 
The first decision rule in this

There are two decision rules in this sec

_[Exogenous hypotheses vs. endogenous hypotheses]_

Similar to The firm still chooses its own location such that it maximises market share, but subject to the predicted movements

The firm makes predictions using the hypothesis that worked best in the past, and continuously updates

be correct, so contrary evidence will weak the hypothesis.  

Here the firm holds several hypotheses on how the other firms choose to locate. The firm acts on the hypothesis that worked best in the past.

attempts to predict the movement  ... based upon their movement history. 

inference / infer

I will concentrate on a  -- firms with inductive rationality. A firm with this decision rule forms hypotheses on how other firms choose their location. The firm holds several hypotheses at once, and acts on the hypothesis that worked best in the past. Each hypothesis attempts to predict the movement of the other agents based on their movement history. The firm still chooses its own location such that it maximises market share, but subject to the predicted movements of other firms generated by its most reliable hypothesis. In addition the firm gradually discards poorly performing hypotheses and forms new hypotheses.

 as opposed to the many-to-one prediction.

_[Although both are multiple agent problems ... This paper differ in that it considers ... ]_
However this paper deviates ... 

_[... Using the procedure first developed for the *Santa Fe Artificial Stock Market* and described by Arthur (2014, chapter 3) and Arthur, Holland, LeBaron, Palmer and Tayler (1996). ... They look at a many-to-one prediction where each agent try to predict the stock price. The agent acts based on this one prediction. The actual stock price is the product of the aggregated behaviour of all agents. This paper looks at many-to-many prediction, where each agents attempts to predict the behaviour of all other agents. Each agents acts based on all of these predictions. And that gives us the aggregated behaviour of all agents ... ]_

* Inductive reasoning: Predict the location of competing firms / hypothesis.
* Two types of learning: Learning through experience (Use the the most reliable hypothesis in any given situation). Learning through evolution (Updating hypothesise: discard poorly performing hypothesis, and form new hypothesis).
(which hypothesis / condition/forecast rules worked well in the past).
* Hetrogenous agents.

-----

By replacing old hypothesis the firm learns 
The replacement of old hypothesis leads the firm to learn 

This adaption price

By discarding and taking in new hypothesis the firm leans

By continuously discarding and  

By using these two decision rules and comparing the results we can separate the effects from 

and in turn analyses the 

By using these two decision rules and comparing the results we can separate the effects from 
We use two decision rules such that we can separate the effect from endogenousisng  hy Since the *maxcov-inductor-GA* decision rule is an extension of the *maxcov-inductor* rule we can analyse the effect of 

In the condition part each of the 13 bits are inherited from one randomly selected parent.

in the condition is passed on by one of the two parents 

The new hypothesis inherits individual bits fro  in the condition is 

of the parent through random replacements and changes.


in the condition part of the most fit parent rule.

The specificity is the number of ones and zeros in the condition part of the rule. The cost $C$ is 
The cost $Cs$ 
that is a cost is placed on rules with many ones and zeros. 

In the mutation method the new hypothesis inherits 
The mutation method selects the most fit parent the 

 and randomly alters the 1, 0, and # in its *condition/forecast* rule, a

For each new hypothesis two parent hypotheses are randomly selected from the  

   The hypotheses with the worst accuracy are discarded.

We use a fitness measure to evaluate the performance of the hypotheses. The fitness

The evolutionary process creates a link between new hypotheses and past hypotheses. Thus the knowledge that past hypotheses have accumulated -- i.e. which hypothesis is accurate and which is not -- is channeled into the new hypotheses. The accumulated knowledge would be lost if new hypothesis were independently creates, say by randomly d

This process channels the knowledge accumulated obtained by ‘learning by using’ into the new hypotheses

_[... evolutionary process ... This process channels the knowledge accumulated by testing predictions into the new hypotheses. ... rather than independently created hypotheses ... ]_	

 **Entry/Exit**

_[market share]_

_[number of surviving parties]_

_[mean age at death]_

_[ ... in high polarisation/two markets ... if there is two firms in the market, then hunting for greater market shares will lead the two firms towards the mean ideal point of all customers ... ]_

Essentially the firms locate in a market where they face competing firms.

Competitive location models are not limited to geographical locations. Location can be the characteristics of a product, a set of political policies, etc.

As hinted above the 

To study such type of competition a growing set of competitive location models have been developed.

Competitive location models are used to study such types of competition. 

In these models firms choose their location in a market where they face competing firms. These model are not limited to geographical locations. Location can be the characteristics of a product, a set of political policies, etc.

In the field of economics competition is often synonymous with price competition. However businesses compete with one-another on a multitude of other factors. Shops compete for customers when they choose their location. Manufactures compete when they choose product characteristic such as size, colour, and shape. Political parties compete for voters when they choose policies. Competitive location models are used to study such types of competition. In these models firms choose their location in a market where they face competing firms. 

, by position themselves somewhere along the line. 

Hoteling’s line market was the first competitive location model. In this model 

As the subsequent literature review shows this model has been extended in terms of the number of firms, the distribution of consumers, and the number of dimensions. 

The literature review section will go into details with this model and t

_[ ... price competition, but how about the many other dimensions on which firms compete ... location models is a good point of departure for this line of inquiry ... since not only geographic location but firm location in product characteristics space ... geographic location is just one characteristic that firms can compete on. But they might also compete on other product characteristics ... ]_

Political parties compete for voters when they choose policies. 

but formulated in terms of the competitive location behaviour of firms.

therefore the agent does not take this into account when deciding where to locate.

since any action on my part 
Since my actions affects other agents, and I take this effect into consideration when choosing my location. 

The lack of foresight in the decision process of agents unfortunately implies the loss of strategic considerations. Strategic considerations that were fundamental to earlier competitive location models.

This unfortunately implies that the strategic considerations -- fundamental to earlier competitive location models -- is absent.

None of the rules employ fore

and discover new insights concerning the competitive location behaviour. 

The approach sets up and runs a computer model in which the agents act using a given set of decision rules. 

The recent political science literature has advanced an alternative approach that relies on agent-based modelling. 

An alternative approach advanced in the recent political science literature uses agent-based modelling.  

Recent advances in political science provide an alternative approach using agents-based modelling. 

 to the competitive location models based.


An alternative approach has been brought forward by recent advances in political science.

Recent advances in the political science literature show an alternative

Inanition solving some location models has been proven to be computationally impossible. 

loving some models has been proven to be computationally impossible.

Research has proven the non-existence of equilibrium in some models, such as models with three firms in the market. This leaves

Research has shown that no equilibrium exist in models, such as the line market with three firms in the market

Inanition research has shown that no equilibrium exist in some models, such as
Research has shown the non-existence of equilibrium in models, such as the line market with three firms in the market, contrary to 

Research has shown that no equilibrium exists in some models. Such as the model with 3 firms in the market.

It has been shown that no equilibrium exist in some models. While other models For some of the models it has been shown that no equilibrium exists. While in other models simply solving the model has been shown to possibly be computationally impossible. 

it has been shown that simply solving the model might be impossible.

Few papers have been published the last 20 years that 

The limited number of papers pr
Traditionally these models have been solved

The extensions have shown that the conclusions drawn from the model are highly sensitive to the particular assumptions used.

However the purely analytical approach of solving for equilibria in the model seems to have reached its limit. This approach 

Analytically solving for equilibrium in the *competitive location models* using a

...
_[ ... advances in the political science literature ... ]_

The sections also discusses how to solve and obtain results from the process that is independent of fore instance the initial position of the firms. 

The results from competitive location models such as Hotelling’s line market and its extensions are covered in the literature review. As is the agent-based model

In addition the paper reintroduces strategic considerations into the competitive location model.

[Fore instance salty-sweetness of chips and the thickness of chips. / mobile screen size]


- [Characteristics are non-ordinal, such consumers do agree that more of a characteristic is better to less, ie. quality would be a ordinal characteristic, on which all consumer agree that better quality is preferable to lower quality.]
- [Characteristics are continuous and infinitely divisible.]

_[saltyness-sweetness and thickness]_. 

The underlying basis is 

in the following models 

. Equilibrium exists if number of firms is large enough, and the location of firms converges to the distribution of consumers’ preferences (Núñez and Scarsini 2014) ... 

 such that we can determine how the location of firms converge over time.

We want to investigate how the parameters of the model affect the results. 

and the full parameter space is huge.

to insure that the results of the models are independent of any particular position.

that only have two parameters — the decision rule and the number of firms — so we use the *grid sweep* method. The two parameter values are discrete and the full parameter space spans of 44 cells or combinations. Four decision rules and number of firms between 2 and 12.
*Grid sweep:*

it should therefore be no surprise that the following outline of the procedure is known as the *experimental design*

*Monte Carlo parameterisation:*
To investigate how the parameters of the model affect the results we employ two different methods. 
_[Grid sweep vs Monte Carlo parameterisation]_

This section reviews the setup and details the execution of the agent-based model. Unlike an analytical model that can be solved mathematically, and where the results and conclusions follow from the derivation of equations, an agent-based model need a more meticulous planning to in order to be able to analyse the results of the model and to insure results that are trustworthy. The type of pre-planning resembles the *experimental design* known from experimental economics.

The model is a M

From this knowledge of the dynamics follow the methods used to estimate the output variables.

guides our choice of method for estimating the output variables.

We can use this knowledge to determine the appropriate method to estimate the output variables.

Satisfying the conditions gives us prior knowledge of the dynamics of the *run*. And we can use this to determine the appropriate method to estimate the output variables.

We first start by showing how a model with a random component can
First we show how models with a random component constitute a *stochastic process*.

We want to estimate the mean value of each of the output variables. 
We will calculate the mean using either the *time average* or the *ensemble average*. 
When selecting between the two it is important to distinguish between the underlying process of a *run* of the model. A run of the model may constitute a deterministic process or stochastic process. In this paper all deterministic process converge to a single state,  but since it is not a unique state, we calculate the mean value of the out
In this paper A deterministic processes in this paper will converge to a single state, however the state
The appropriate method will depend on the

When choosing the method it
The choice of method depends on whether the model represents a  

First we show how models with a random component constitute a *stochastic process*. Laver and Sergeant (2011) note that most computational models can be represented by a time-homogenous Markov chain. So we put forth the conditions that a *stochastic process* needs to satisfy for it to represent a time-homogenous Markov chain. Satisfying the conditions gives us prior knowledge of the dynamics of the *run*. And we can use this to determine the appropriate method to estimate the output variables.

Markov chain … different processes and what is known about convergence of these process … burn in … and finally arrive a the appropriate method used to estimate the output variables. We will use mean estimates across iterations for a single repetition, or across repetitions at a single iteration.
We use this and previous 
We briefly discuss  different process and their 
of the time-homogenous Markov chain

 This in turn implies that a *run* which consists of multiple *repetitions* constitutes a *stochastic process*. with a random component

that contain a random component and a finite state space
All time-homogenous Markov chains converge to at least one steady state. 
While process that are *ergodic* converge to a unique distribution vector $\pi_\infty$.
Not all time-homogenous Markov chains are *ergodic*, but as 

We let $s$ denote the dimension of the state space, that is the number of possible states. The transition probability matrix $\rm P$ is a $s \times s$ matrix with all the one-step transition probabilities. The *state space distribution vector* $\pi_t$ represents the unconditional probability distribution of the state space at time $t$. Each element $i$ in the vector describe the probability that the process will be in state $i$ at iteration $t$. The size of the *state space distribution vector* is $s \times 1$. The *state space distribution* then evolves as given by $\pi'_{t+1} = \pi'_t \rm P$. Knowing the initial state space distribution, $\pi_0$, we can derive the vector $\pi_t$ using $\pi'_t = \pi'_0 {\rm P}^t$.

We have laid out the specifications of our model and now turn to the methods used to estimate the output variables of the model. In choosing the appropriate method it is important to distinguish between the underlying process of a *run* of the model. We use different methods depending on whether the *run* constitutes a *deterministic process* or a *stochastic process*. We first show that a stochastic component in our model allows us to view a *run* of the model as a *stochastic process*. Laver and Sergeant (2011) note that most computational models can be represented by a particular *stochastic process* known as the *time-homogenous Markov chain*. We present the necessary conditions for a *time-homogenous Markov chain*. We have prior knowledge of the dynamics of the process — in particular convergence and steady state — when the model satisfy these conditions. And knowing the dynamics of the process lets us construct methods that give accurate estimates of the output variables.

In choosing the appropriate method it is important to distinguish between the underlying process of a *run* of the model. 

We use different methods depending on whether the *run* constitutes a *deterministic process* or a *stochastic process*. 

We make a distinction between the time-homogenous Markov chains that contain a random component (besides the randomly drawn initial positions), and those that do not. A *stochastic time-homogenous Markov chain* contains a random component. 

If the time-homogenous Markov chain contains a random combo

are non-ergodic and

A *deterministic time-homogenous Markov chain* converges to a single state

**Deterministic process**
To evaluate whether a process has “burnt in” or not we need to distinguish between deterministic processes that converge to a single state, and stochastic processes that converge to a distribution of states. Deterministic processes are a subset of stochastic processes where the probability that the random vector $Y_t$ takes on particular values is 1. In general there is no guarantee that a deterministic process will converge to a single state, it could oscillate between several states. However all deterministic process in this paper are non-ergodic and converge to a single state. 

determining whether 

We cannot use the output variables in

This prohibits us from using any of the output variables in transient states. We discard the

The Markov property requires that the probability of a future state of the process depend on the current state and not on any of the previous state of the process.

… random component such as when the a hunter-firm turns around and heads in a random direction (not the random initial position) …

So the iteration parameter does not affect the probability: 

The *deterministic process* is a subset of the stochastic process, where the random vector takes particular values with probability equal 1. 

For each iteration $t$, t
In the experimental design we use
The random seed is the number used to initialise the pseudorandom number generator, that in turn is used to randomly draw initial positions of firms.
relation 
that is the range of possible values of the random vector. 

When the condition of the time-homogenous Markov chain are satisfied, we have prior knowledge of the dynamics of the *run*. 

Thus a *ergodic* process converges to the unique state space distribution
For a *ergodic* process the unique state space distribution is independent of the particular repetition. affect So if the process is *ergodic* the state space distribution is independent of the particular repetition, 

In the limit as the total number of iterations go to infinity the 

We model the realised value of $\mu^{(n)}$ for a given repetition as a random variable drawn from distribution with mean $\mu$ and standard deviations $\sigma_\mu$.

There are several repetitions and not j
Looking across the

In steady state, by definition the state space distribution vector is *stationary*, so we have that $\mu_t^{(n)} = \mu_{t+1}^{(n)} = \mu_{t+2}^{(n)}$ and so on, for all repetitions $n$. 

And so we remove the time subscript and define $\mu^{(n)}$ as the expected value of $Y_t$ for repetition $n$ over all iterations $t$. 

We define the expected value of $Y_t$ for repetition $n$ as $\mu_t^{(n)}$. 

We only consider output variables in steady state.
We want an estimate of the output variables in steady state.
Our goal is to calculate the mean value for each of the output variables in steady state. 

trace plots. The trace plots display the iterative history of a repetition. No trends, just consistent noise around a stable mean.

, such that the *time average* gives a representative estimate of $\mu$.

Whenever the underlying *stochastic time-homogenous Markov chain* is *ergodic* we estimate using the *time average*.

and we use the 

There is less potential to trim with a low R-hat statistics, and in the limit the measure tends to one – indicating that process has map out the entire steady state distribution.

Only when the process has mapped out the entire distribution can we be assured that the *time average* gives a representative estimate of $\mu$. 

This may not be the case when using the *time average*

If we feel confident that the process has mapped out the entire distribution then we will use the *time average* give a representative estimate of $\mu$. If this is not the case we will resort to using the *ensemble average*.

To check whether enough observations have been collected to map out the steady state distribution vector we run several test repetitions. 

[We use the *R-hat statistic*[^rhat] to check whether enough observations have been collected to map out the steady state distribution vector (Laver and Sergeant 2011, Brooks and Gelman 1998). The R-hat statistic compares between-repetition variance to the total within-repetition variance. A low R-hat statistic implies less potential to reduce the state space distribution vector from increasing the number of iterations. We run several test repetition and calculate the R-hat statistic. The R-hat statistic tends to 1 in the limit. We use the common cutoff threshold level for the R-hat statistic of 1.05. If the R-hat statistic is below this threshold level, then we feel confident that the process has mapped out the entire distribution such that the *time average* gives a representative estimate of $\mu$, otherwise we use the *ensemble average*.]

[We check whether enough observations have been collected to map out the steady state distribution vector by visually inspecting the density plots.]

We use the maximum of all test repetition as the *burnin* iterations is set
Each test repetition returns
From each test repetition we get a specific 
From all test repetitions we select the maximum number iterations need to fulfil this 

Deterministic process: burnt in once values don’t change, ie. the process is stationary. Empirically we set the burn in period to the maximum number of iterations it takes before the output variables flatline[^deterburn].  

For the stochastic process we can in theory do the same, however since the process converges to

Each test repetition returns a burnin iteration, and the largest of these is set as the number of *burnin* iterations in the final execution of the model.

We execute a test run, where each repetition has say 100 iterations. For each run we find the first iteration where the value of the output variable is equal to the value at the 100th iteration. From all repetitions we select the largest of these iteration numbers, say the 69th iterations. This is then number of iterations needed for the process to burn in. In the final execution of the model we err on the side of caution and set the number burn in iterations slightly higher, say 100 iterations.

This is done by visually inspecting the trace plots of a few repetitions from different runs of the model. 

Stochastic process: In theory the same, however since the process converges to a distribution of states rather than a single state, it is in practice more difficult to determine when the process has burnt in.
Empirically: 

**convergence / burn in**
_[runs, repetitions, iterations.]_

### Deliberate (re)action to location of competitors
### Competitors – a deliberate consideration
### Deliberately 
### Competitor awareness
### Receptive to the location of competitors 

_[Similarly to experimental studies we rely on randomisation to validate estimated effects.]_

_[The end of this section discuss *burn in*, that is how long the model needs to run in order to converge.]_

 $y_t^{(n)}$ for all iterations $t$ for a given repetition $n$. A plot of one value of the vector $y_t^{(n)}$ by iteration.

[TO-DO: make density plots (include in paper — DON’T INCLUDE SINCE DENSITY PLOTS WILL ALSO CONTAIN TRANSIENT STATES). Switch MCP all-hunter model to ensemble average instead. ].

In addition because of the symmetry and zero covariance ($\rho = 0$) between x and y, we can use the mixed univariate normal distribution, $f_x$, to determine the x coordinates of peaks and saddle points.

$$= \frac{2e^{-2(x-\mu_{x,i})^2 - 2(y-\mu_{y,i})^2}}{\pi}$

, and to discover new insights, such as out-of-equilibrium and transitional location behaviour.

When analysing the model we execute many repetitions of the model with varying combinations of input parameters. Executing one model can easily entail hundreds of thousands of iterations and thus millions of calculations.

  calculations
A thus model will easily into

The model is analysed by executing hundreds of repetitions of the model hundreds of different combinations of input parameters. The computational resources needed to execute this number 

With no overlap we are at the edge of what constitutes a single market[^singlemarket], and it might be more appropriate to describe this setting as two separate markets, at least in terms of the customers.

[^singlemarket]: _[Definition of market: ... When is it a single market and when is it two separate markets ...]_

_[Short recap of the definition of a agent-based model]_
 The model executes several iteration and analyses how the interaction of the firms affect the overall location of firms.

Our point of departure is that each firm chooses the location that maximises its market share, given the location of the other firms. 

 since t  These rule are described in detail below. _[rational vs. rule of thumb]_
_[Why these three rules? No exploration, social optimum, and high on exploration.]_

would result in the largest market share.

Comparing this to one where the triangle which the firm locates within is selected randomly  be correct in 4-16% of all cases. The exact percentage depends on the parameter settings and the number of firms. 

selected which the triangle would only
the method is correct 40-90% of the cases 

ends up gives the firm the largest market share.

The actual market area or consumers that the firm attracts by locating within the triangle, does not

The consumers that the firm attracts will not necessarily be all the ones in the triangle. Therefore the triangle with most consumers may not always be the triangle that gives the firm the largest market share. However the method is correct 40-90% of the cases depending on the parameter settings and the number of firms. If the triangle was randomly selected which the triangle would only be correct in 4-16% of all cases.

Each firm has to calculate the market share of at most 24 triangles. If 12 firms all use the *MAXCOV*-rule the total number of triangles in each iteration would be 288.

 We opt for the gradual adjustment for two reasons: 
 
The *maxcov* firm does not move directly to the ideal position, but moves 0.1 standard deviations in the direction.

 ,  may oscillate between several states.

We see that each firm can gain a higher makes  When firms are located 0.44 standard deviations from the population centre, 

We
By moving closer to the population centre the firm can capture the high density area, but the losses clearly outweighs this gain. _[A firm that attempts to wedge its market area closer to the centre will often find as a result that the far end of its wedged market area becomes increasingly thinner. This is the lost market area.]_ 

_[Although Núñez and Scarsini (2014) investigates a discrete competitive location model we find similar results. Namely that as the number of firms increase the location of firms converges to the distribution of consumers’ preferences. In this model we see that as the number of firms in the market increases the mean representation converges towards the social optimal level.]_

With each crowd of firms fiercely competing for the customers in the respective subpopulation. 

locate around the peak of the customer distribution.

 Firms locate close to the centre of one of the subpopulations

The firm loses market shares when it moves too far away from the centre of a subpopulation. Thus this acts as a punishment for the *hunter* firm discouraging it from locating between the subpopulations and close to the average ideal point of all customers.

A highly polarised market with two firms solely focused on increasing their market shares, leads the firms to locate in a position where fierce competition is present. That is the firms cluster and compete for the same locations, rather than disperse across the market space. Note that this behaviour is a combination of the polarisation and the hunt for market shares. 

 the inter
The other decision rules also show that firms cluster when there is little to no polarisation, but only the *hunter* firms maintain this clustering when the polarisation among the subpopulations increases. The effect depends upon the interplay between decision rule and population distribution.

With a high degree of polarisation the *maxcov* firms always separate, also with two or three firms in the market. And the firms locate around the centre of each subpopulation. 

which imply that the ENP increases.
The low effective number of firms in the *aggregator* model with many firms and low polarisation the centre of the symmetric distribution easily overcrowds. In the *aggregator* model where firms locate to please their current customer base overcrowding leads to firms locating on different orbits around the centre. Firms located on the inner orbits attract a larger share of the customers than the firms located on the orbits further away from the centre. Polarisation of the subpopulations spreads the ideal points over a greater area which in turn reduce the overcrowding of firms. This is why in the *aggregator* model with many firms the ENP increases when going from low polarisation to medium or high degree of polarisation.

 The crowd competes for the customers in each subpopulation.

_[ ... Simultaneous ... heterogeneous agents ... infinite regress ... Note that the lack of a solution to the maximisation problem is not the result of bounded rationality, ie. mental capacity of the agents need to calculate the correct solution. We have make no such restriction. Agents have unbounded rationality. ... ]_

_[ ... Is it possible to adequately describe the state of all competing firms using a single measure, rather than one measure for each competing firm. Possible something based on the Delaunay triangulation/graph (graph properties such as eccentricity/radius, circumference/geodesic, diameter, degree) ... ]_

In addition it is easy to expand the current *maxcov-inductor* decision rule to include

Instead of using *condition/forecast*-rules to predict the future location of competing firms, one could also use a *neural network*.
_[... why use this method rather than for instance neural net/machine learning method? ... easy to expand to include the evolutionary process used in the next decision rule ... clear to see which information is used to make forecasts / how firms make forecast, while the neural net is a black box (it would work, but difficult to analysis how it works) ... ]_

 not. Each *maxcov-inductor* firm has a unique set of hypotheses.

That is each crowds reach their critical level of maxcov-firms that they can stably sustain with a total of seven firms in the market. 

 a less uneven subpopulations is needed for 

implying a lower critical level. When the left subpopulation is half as large as the right, we still observe oscillation in the maxcov-model, while the maxcov-inductor firms are more likely to locate in the triangle configuration.

As the relative size of the left subpopulation increases the centre firms oscillate between locations that are closer and closer to the peak of the left subpopulation.

   From this it is clear that as the relative size of the subpopulation increases and the two

  and we see a decrease in mean eccentricity as some firms start to them

 than it was in the maxcov model.   that tops with seven firms in the market is slight more evident 
as the number of firms firms in the market is increased is 
With a low and medium degree of polarisation of the subpopulations the maxcov-inductor firms locate at similar distance to the ideal point of all consumers as the maxcov model. With a high degree of polarisation in the maxcov-inductor model the mean eccentricity increases steadily and tops with seven firms in the market. 

in market with highly polarised subpopulation ($\mu=1.5$) and where left subpopulation is half as large as right subpopulations ($n_l/n_r = 1.5$). The black cross indicates the mean ideal point of all consumers.

_[Not locked into position. The average distance to the population centre is about the same. Locates closer the average ideal point along the dimension with no disagreement (that is closer to y=0).]_
_[Mean eccentricity: no change compared to *maxcov* model.]_
_[ENP: falls since some firms are endowed with more accurate condition/forecast rules.]_

The mean representation is largely unchanged from the maxcov model and maxcov-inductor model.

 2 and more, then oscillation would 
That is from the auto correlation function of respectively x any y coordinates the firm only uses information from the 1-lag operator

 The current state descriptor of competing firms calculates the auto correlation function of  the 1 lag operator in  Firms only use the 1 lag operator in the auto-correlation . In interesting extension to the model might include multiple lag operators, such that firms were also capable of recognising oscillations with frequencies of 2 or 3 periods. … 

   in particular influences the location of  In sum … a maxcov-inductor firm observes the oscillation of competing firms and uses this information to make predicts. The firm locates based not the predicted future location of competing firms, which precludes the most obvious suboptimal actions of the firm. 
, but the most rudimentary oscillation patterns does.

This implies that the switch from oscillation to triangular configuration takes place at more equal-sized subpopulation   requires a less uneven subpopulations to take place in the maxcov-inductor model. 

This is also evident from figure _[##]_, where we, for both models, plot the trajectories from four firms with $\mu=1.5$ and $n_l/n_r = 1.5$. 

And so competition among firms do not
, and not just . So firms are not force
When firms are 
The continuous competition for these consumers,  
The continuous competition for these consumers, eliminates the clustering of firms.

A firm  tactic
can temporarily strategy

The firms 
The location Firms may lock in, however
The firms are unlikely to lock in to

The firms recognise  the oscillation 
 
there are several different location configurations which the two firms on the left might lock into. Additionally the location of the two firms on the left often oscillates. 

_[Mean eccentricity: When there are few firms in the market then the firms locate further from the population centre. [Closer to y=0. The location perimeter / boundary of where firms locate has along the x-axis has not changed. The firms will only locate out to a certain point/distance, that is not too far away from the centres of the subpopulations. Thus the mean eccentricity tells us that firms to a greater extend locate in between the subpopulations, and that this behaviour increases as the number of firms increase. This is why we see a decline in the mean eccentricity as the number of firms increase. This is not a stable location pattern, but instead it reflects that firms in transition -- relocating from one subpopulation to the other.]]_
_[ENP: low. The firms end up locating at the subpopulation centre.  The firms separate into two crowds: the crowds are uneven in size. => low ENP. When firms locate on top of each other ==> the firms very likely to lock into position.]_

 any particular firms … has been eliminated … In the maxcov-inductor model a

We focus on the market with three firms, since no pure strategy equilibrium[^threeequilibrium].
[^threeequilibrium]: Shaked (1975) proved this

_[In the all-hunter, all-aggregator and all-maxcov models all firms use the same decision rule. So no firm had a long-run advantage of its competitors. This will not be the case in the all-maxcov-inductor model, since one firm might be endowed with a more competitively advantageous set of hypotheses, than its competitors.]_ Additionally the information used to update the accuracy of hypotheses also differ from firm to firm, because it is based on their respective hypotheses. 

Increasing the degree of polarisation increases
When completely symmetric firms locate around 
When the consumer distribution is sufficiently asymmetric (when $n_l/n_r$ is not too close to 1), the five firms will split into two crowds. With the degree of polarisation close to 1.5 the firms tend to locate in a three-two split, when the degree of polarisation is close to 1, the split tends to be four-one.
With a sufficiently uneven subpopulations five firms will 

  is not the results of a overall break down  Thus during the transition for the three-two split to the four-one split they predict
While the acc
 , but at
  should be viewed as a

, a new set of hypotheses that more accurately predict the future location of all competing firms

With many firms competition lead firms to locate around the peaks of the distri

 The exempt is the *all-sticker* model where firms do not interact. And *hunter* firms in certain settings. 

 The mean representation in almost all models where firms Very little effect on 

Some the degree of c
 The preferences of consumers are often correlated, making it more appropriate to assume that consumers are lump together subpopulations. Subpopulations may arise due to social interaction among consumers. Social conformity

Natural setting:

The locations that firms choose to locate at are mainly determined by the method the firm use locate. to pick the location that maximises market share.

_[decision rule with foresight]_

Strategic consideration

, and not just in terms of the location they choose. the firms are heterogeneous in terms of their location and the information and knowledge.

The exception 
The exception in this paper was the market with less than four *hunter* firms and a bimodal distribution of consumers. 

If the firms in the market solely focus on increasing their market share, and there is less firms than peaks in the distribution function, then competing significantly reduces the welfare of consumers.

 disperse the density of consumers over a larger area

In the limit as the   dispersed over a larger 
  seems to be the main explanation for
 The explanation for these differences is the choice of distribution function. 
The choice of distribution function is most like the 
Part of the explanation is due to the non-uniform distribution of consumer preferences. 

We investigate how the average utility of consumers compare with the model where all firms use the *aggregator* decision rules, which minimises the average distance between consumers and firms. 

firms when the number of firms is less than twice the number of peaks in the distribution f

in the *hunter* and all the *maxcov* models 

Further methods are need to find the optimal location of firms already in the the market, that consider relocating.

 to find the location that maximises the market share of the firm.

The model would benefit ennui

the number of firms in the market through the, and
The natural next step: 
* price competition
* Engdonenoise the number of firms in the market.
* we use a rough approximation in all the *maxcov* decision rules to find the location that maximises the market share of the firm, in lack of methods developed to find optimal location. Further methods are need to find the optimal location of firms already in the the market, that consider relocating.

The randomly drawn set of hypothesis affects the initial state space distribution $\pi_0$, and should not be considered a random component in the process.

 All the condition/forecast rules that matches the current state of firm $j$, are said to be active. 

That is where the condition of the rule is satisfied by the current state descriptor, $J_j$.
all the conditions that

Since a hypothesis might only be relevant to a narrow set of situations, the firm
With condition part of the *condition/forecast* rule, the firm is able to recognise different location patterns of competing firms, and apply .  

Among these active condition/forecast rules, the rule with the best accuracy is used to forecast the future location of firm $j$. 

 by matching the conditions with the current state descriptor of competing firms.

At every iteration and for each competing firm $j$, the firms selects the *condition/forecast* rules that match the current state descriptor, $J_j$.

When the conditions in the *condition/forecast* rule matches the current state descriptor, $J_j$, of competing firm $j$, the *condition/forecast* rule

  is assume to be is 

$\alpha_a$ is the memory parameter and

 And $s_m$ is the specificity of rule $m$ calculated as the number of ones and zeros in the condition part of the rule (i.e. all the # are not counted).

Where $M$ is the number of *condition/forecast* held by firm $i$, since this is constant and identical across firms the term can be left out. 

 if crossover or mutation is used to create the new condition/forecast rule. The crossover method is used with probability $p$, and mutation method with probability $1-p$. 


Many have gone this path before.
Although the there is a lack of equilibrium solutions lack in  
The motivation is not to 
The motivation for using the agent based model in this paper ... is discover  not to check Nash-equilibrium conditions, .. The objective is not to check Nash-equilibrium conditions ... equilibrium behaviour vs equilibrium results ... but to ... lag of equilibrium solutions/benchmark, thus risking that fitting the model such that it replicates the eq. in N=2 2D, does not carry over to $N>2$. ... product differentiation is dynamic and evolving process, hard to imagine the process settles down to a static equilibrium state 

	Hypotheses are endogenous in this decision rule
	
	 The  And how firm with a majority of consumers one firm is able to capture a predominant share of customers    The paper augment
	
	 The paper constructs a agents-based model
	The paper constructs an agent-based model with fore
This paper set out to reintroduce foresight and thus strategic consideration into the competitive location model,
The natural setting when considering competitive location or competitive product differentiation is a market with few firms where firms act strategically and with foresight. The choice of each firm reflects the diversity of consumer preferences and so the aggregated distribution of consumer preferences is likely to be of great importance. Moreover the aggregated distribution of each consumer's preferred product or location does not necessarily follow a convenient uniform, symmetric or even unimodal distribution. The distribution may well be asymmetric and multi-modal.
With this method firms use \emph{inductive reasoning}, i.e. they hold several hypotheses on how a competing firm chooses to locate, and use the most probable hypothesis given the current state to predict the future location of the competing firm. The firm gradually discard poorly performing hypotheses and form new hypotheses. The model is dynamic and firms act simultaneously. The results of the model are derived by observing how the interaction of firms play out. 
This paper finds that predictions by themselves have a limited effect on the overall location pattern of firms.
The interacting effect of firms competing for consumers seems to results in locations that are more or less on par with the social optimal location.